# 第 1 章：什麼是機器學習？

> **「如果你無法向一個六歲小孩解釋清楚，那你自己也不夠理解。」** — 愛因斯坦

---

## 🎯 本章目標

讀完這一章，你將能夠：

- [ ] 用自己的話解釋「機器學習」與「傳統規則系統」的差異
- [ ] 區分監督式學習與非監督式學習
- [ ] 解釋為什麼要把資料分成訓練集與測試集
- [ ] 理解過擬合（Overfitting）是什麼、為什麼危險
- [ ] 用 scikit-learn 跑出你人生第一個 ML 模型

---

## 故事時間：銀行的兩難

想像你是一家銀行的風控主管。每天有上千筆信用卡申請送到你桌上，你必須決定：
**核准？還是拒絕？**

你的團隊目前用一套「規則系統」來判斷：

```
如果 年收入 > 80 萬 且 信用紀錄無不良 且 工作年資 > 2 年：
    → 核准
否則：
    → 拒絕
```

聽起來很合理，對吧？但問題來了——

### 5% 的判錯，代價有多大？

假設你的系統每個月處理 10,000 筆申請，有 5% 判錯率：

```
10,000 筆 × 5% 判錯 = 500 筆判錯

判錯分兩種：
┌─────────────────────────────────────────────────────────┐
│  類型 A：把「好客戶」誤判為「壞客戶」（拒絕了他）       │
│  → 損失一個優質客戶的終身價值                           │
│  → 假設每個客戶值 50 萬，250 筆 = 1.25 億損失           │
│                                                         │
│  類型 B：把「壞客戶」誤判為「好客戶」（放行了他）       │
│  → 壞帳、呆帳，真金白銀的損失                           │
│  → 假設每筆壞帳 30 萬，250 筆 = 7,500 萬損失            │
└─────────────────────────────────────────────────────────┘

一個月的錯誤成本：將近 2 億元！
```

這就是為什麼「稍微提升一點準確率」在真實世界中價值巨大。

---

## 規則系統 vs 機器學習

### 傳統規則系統：人寫規則

```
人類專家 → 分析資料 → 寫出規則 → 系統按規則判斷
                         ↓
                    「如果 A 且 B → C」
```

**優點：**
- 規則透明、可解釋
- 容易除錯（找到哪條規則出錯就改）

**缺點：**
- 規則越來越多，互相矛盾
- 無法處理微妙的模式（例如：年收 79 萬但其他條件超好的客戶）
- 世界在變，規則沒跟著變

### 機器學習：讓資料說話

```
歷史資料（有答案的）→ 演算法自動找規律 → 學出模型 → 模型預測新資料
                                          ↓
                                   「從資料中學到的規則」
```

**優點：**
- 能發現人類看不出的模式
- 資料更新後，模型可以重新學習
- 處理高維度資料（幾百個特徵同時考慮）

**缺點：**
- 模型可能是「黑盒子」（不好解釋）
- 需要大量且乾淨的資料
- 垃圾進、垃圾出（Garbage in, Garbage out）

### 💡 重點觀念

> **機器學習不是寫程式告訴電腦「怎麼做」，而是給電腦資料，讓它自己「學會怎麼做」。**

用一張表來比較：

```
┌──────────────┬──────────────────┬──────────────────┐
│              │  傳統規則系統     │  機器學習         │
├──────────────┼──────────────────┼──────────────────┤
│  輸入        │  規則 + 資料     │  資料 + 答案      │
│  輸出        │  答案            │  規則（模型）     │
│  維護        │  人工更新規則    │  重新訓練模型     │
│  擴展性      │  規則爆炸        │  資料越多越好     │
│  適用場景    │  邏輯明確的問題  │  模式複雜的問題   │
└──────────────┴──────────────────┴──────────────────┘
```

---

## 監督式學習 vs 非監督式學習

機器學習有好幾個分支，但最重要的兩大類是：

### 監督式學習（Supervised Learning）

> 類比：就像考試前老師給你「題目 + 標準答案」讓你練習。

```
訓練資料 = 特徵（Features）+ 標籤（Labels）

例如信用評分：
┌────────┬──────┬────────┬──────────┬─────────┐
│ 客戶   │ 年收 │ 工作年資│ 信用紀錄 │ 結果    │
├────────┼──────┼────────┼──────────┼─────────┤
│ 小明   │ 90萬 │ 5年    │ 良好     │ ✅ 核准 │
│ 小華   │ 40萬 │ 1年    │ 不良     │ ❌ 拒絕 │
│ 小美   │ 70萬 │ 3年    │ 良好     │ ✅ 核准 │
│ 小強   │ 60萬 │ 2年    │ 不良     │ ❌ 拒絕 │
└────────┴──────┴────────┴──────────┴─────────┘
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^
              特徵（X）                標籤（y）
```

**常見任務：**
- **分類（Classification）**：預測類別（好/壞客戶、貓/狗、垃圾郵件/正常郵件）
- **迴歸（Regression）**：預測數值（房價、溫度、股價）

### 非監督式學習（Unsupervised Learning）

> 類比：沒有標準答案，讓你自己把相似的東西分成一堆。

```
訓練資料 = 只有特徵（Features），沒有標籤

例如客戶分群：
┌────────┬──────┬────────┬──────────┐
│ 客戶   │ 年收 │ 消費頻率│ 平均消費 │  ← 沒有「答案」欄位
├────────┼──────┼────────┼──────────┤
│ 小明   │ 90萬 │ 高     │ 5,000    │
│ 小華   │ 40萬 │ 低     │ 500      │
│ 小美   │ 85萬 │ 高     │ 4,500    │
│ 小強   │ 45萬 │ 低     │ 600      │
└────────┴──────┴────────┴──────────┘

演算法自動分群：
  群組 A（高收入高消費）：小明、小美
  群組 B（低收入低消費）：小華、小強
```

**常見任務：**
- **分群（Clustering）**：把相似的資料點歸在一起
- **降維（Dimensionality Reduction）**：簡化資料但保留重要資訊

### 🧠 動動腦

以下哪些是監督式學習，哪些是非監督式學習？

1. 根據過去的交易紀錄，預測客戶是否會違約
2. 把新聞文章自動分成「政治」「體育」「娛樂」等類別（有標註資料）
3. 分析超市購物籃，找出哪些商品經常一起被購買
4. 預測明天的氣溫

<details>
<summary>點我看答案</summary>

1. **監督式** — 有明確的標籤（違約 / 不違約）
2. **監督式** — 有標註的類別標籤
3. **非監督式** — 沒有預定義的答案，是發現隱藏模式
4. **監督式** — 預測具體數值（迴歸問題）

</details>

---

## 為什麼要分訓練集和測試集？

這是整門課最重要的觀念之一。讓我用一個比喻：

### 考試的類比

> 想像一個學生，他拿到了「考古題 + 答案」來準備考試。
>
> - **情境 A**：考試出的是跟考古題一模一樣的題目 → 他答對了 100%！
>   但這代表他真的學會了嗎？不一定，他可能只是背答案。
>
> - **情境 B**：考試出的是全新的題目（但範圍相同）→ 他答對了 85%。
>   這才是他「真正實力」的反映。

機器學習的邏輯完全一樣：

```
全部資料
┌───────────────────────────────────────────┐
│                                           │
│   ┌─────────────────────┐ ┌────────────┐ │
│   │                     │ │            │ │
│   │    訓練集 (80%)     │ │ 測試集(20%)│ │
│   │   Train Set         │ │ Test Set   │ │
│   │                     │ │            │ │
│   │   模型在這裡學習     │ │ 在這裡驗證 │ │
│   │                     │ │ 真正實力   │ │
│   └─────────────────────┘ └────────────┘ │
│                                           │
└───────────────────────────────────────────┘
```

**訓練集（Training Set）**：模型用來學習的資料（就像練習題）
**測試集（Test Set）**：模型從未見過的資料，用來評估真實表現（就像正式考試）

### ❓ 沒有笨問題

**Q：為什麼不能拿全部資料來訓練？不是資料越多越好嗎？**

A：資料多確實好，但如果你用全部資料訓練，就沒有「從未見過的資料」來測試了。
你測出來的分數，只是模型「背答案」的能力，不是「真正解題」的能力。
這就像老師用考古題當正式考試——分數很高但毫無意義。

**Q：那比例怎麼分？80/20？70/30？**

A：常見的分法是 80% 訓練 / 20% 測試，或 70% / 30%。
資料量很大時（幾十萬筆以上），測試集可以小一點（如 90/10）。
資料量小時，可能需要更進階的方法（如交叉驗證，後面章節會教）。

**Q：測試集可以拿來調整模型嗎？**

A：絕對不行！這是初學者最常犯的錯誤。測試集只能在最後「考試」時用一次。
如果你反覆用測試集調整模型，就等於偷看答案了。
（後面章節會介紹「驗證集 Validation Set」來解決這個問題）

---

## 過擬合：模型的「死背」症候群

### 什麼是過擬合（Overfitting）？

> 類比：一個學生把 100 題考古題的答案全部背下來了，包括題號。
> 問他第 37 題答案是什麼，他秒答「C」。
> 但換個方式問同樣的觀念，他就答不出來了。

```
過擬合的模型：

訓練集準確率：99.5% 🎉    ← 哇，好厲害！
測試集準確率：62.3% 😱    ← 等等...這也差太多了吧？

     ↑ 這個巨大的落差，就是過擬合的訊號
```

### 圖解過擬合

想像我們要畫一條線，把藍色圓點和紅色三角形分開：

```
好的模型（恰到好處）：         過擬合的模型（太複雜）：

  ○ ○                           ○ ○
 ○  ○  |  △ △                 ○  ○ ╲╱ △ △
○  ○   | △  △                ○  ○╱╲╱╲△  △
 ○ ○   |  △                   ○ ○╲╱╲╱ △
  ○    | △ △                    ○╱╲╱╲△ △

簡單的直線，               扭來扭去的曲線，
大方向正確。               完美貼合每個訓練點，
新資料來了也能              但新資料來了就 GG。
正確分類。
```

### 💡 重點觀念

> **過擬合 = 模型學到了「訓練資料的雜訊」而不是「真正的規律」。**
>
> 好的模型應該學到的是通用規律，而不是個別資料點的特殊性。

### 如何察覺過擬合？

```
┌─────────────────────────────────────────────────┐
│  訓練準確率 vs 測試準確率                        │
│                                                 │
│  情況 1：訓練 95% / 測試 93% → ✅ 正常          │
│  情況 2：訓練 99% / 測試 65% → ❌ 過擬合        │
│  情況 3：訓練 60% / 測試 58% → ⚠️ 欠擬合       │
│                           （模型太簡單，學不夠） │
└─────────────────────────────────────────────────┘
```

---

## 動手做：你的第一個 ML 模型

終於到了寫程式的時間！我們用 scikit-learn 內建的鳶尾花（Iris）資料集。

### 認識 Iris 資料集

```
鳶尾花資料集：150 朵花，3 個品種，4 個特徵

特徵（Features / X）：
┌──────────────────┬───────────────┬──────────────────┬───────────────┐
│ sepal length(cm) │ sepal width   │ petal length(cm) │ petal width   │
│ 花萼長度          │ 花萼寬度      │ 花瓣長度          │ 花瓣寬度      │
├──────────────────┼───────────────┼──────────────────┼───────────────┤
│ 5.1              │ 3.5           │ 1.4              │ 0.2           │
│ 4.9              │ 3.0           │ 1.4              │ 0.2           │
│ 7.0              │ 3.2           │ 4.7              │ 1.4           │
│ ...              │ ...           │ ...              │ ...           │
└──────────────────┴───────────────┴──────────────────┴───────────────┘

標籤（Labels / y）：
  0 = Setosa（山鳶尾）
  1 = Versicolor（變色鳶尾）
  2 = Virginica（維吉尼亞鳶尾）
```

### 第一步：載入資料

```python
# 載入必要的套件
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 載入鳶尾花資料集
iris = load_iris()

# 看看裡面有什麼
print("特徵名稱：", iris.feature_names)
print("類別名稱：", iris.target_names)
print("資料形狀：", iris.data.shape)     # (150, 4) → 150 筆資料，4 個特徵
print("標籤形狀：", iris.target.shape)   # (150,)   → 150 個答案
```

輸出：
```
特徵名稱： ['sepal length (cm)', 'sepal width (cm)',
           'petal length (cm)', 'petal width (cm)']
類別名稱： ['setosa' 'versicolor' 'virginica']
資料形狀： (150, 4)
標籤形狀： (150,)
```

### 第二步：分割訓練集和測試集

```python
# 把資料分成訓練集和測試集
X = iris.data      # 特徵
y = iris.target    # 標籤

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,      # 20% 當測試集
    random_state=42      # 固定隨機種子，確保結果可重現
)

print(f"訓練集大小：{X_train.shape[0]} 筆")  # 120 筆
print(f"測試集大小：{X_test.shape[0]} 筆")    # 30 筆
```

### ⚠️ 常見陷阱

> **random_state 是什麼？為什麼要設定它？**
>
> `train_test_split` 會隨機打亂資料再切割。如果不設定 `random_state`，
> 每次執行結果都不同，你的同學跑出來的數字會和你不一樣。
>
> 設定 `random_state=42`（或任何固定數字）就像「固定洗牌方式」，
> 確保每次切出來的訓練集和測試集完全相同。
>
> **42 有什麼特別的嗎？** 沒有，這是《乞丐趕廟公》（又譯《乞力馬乍羅旅人》，原名
> The Hitchhiker's Guide to the Galaxy）裡「生命、宇宙及萬事萬物的終極答案」。
> 在 ML 社群中只是一個約定俗成的慣例。用 0、1、123 都完全可以。

### 第三步：訓練模型

```python
# 建立邏輯迴歸模型
model = LogisticRegression(max_iter=200)

# 用訓練集訓練模型（fit = 學習 = 訓練）
model.fit(X_train, y_train)

# fit 做了什麼？
# 模型看了 120 筆「題目+答案」，自動找出分類的規律
```

### 第四步：預測與評估

```python
# 用測試集預測（模型從未看過這些資料）
y_pred = model.predict(X_test)

# 計算準確率
accuracy = accuracy_score(y_test, y_pred)
print(f"測試集準確率：{accuracy:.2%}")
```

輸出：
```
測試集準確率：100.00%
```

### 第五步：看看模型到底預測了什麼

```python
# 對比預測結果和真正答案
import numpy as np

print("預測值：", y_pred)
print("真正值：", y_test)
print("預測對了幾筆：", np.sum(y_pred == y_test), "/ ", len(y_test))
```

### 🧠 動動腦

為什麼 Iris 資料集的準確率這麼高（接近 100%）？這在真實世界中常見嗎？

<details>
<summary>點我看答案</summary>

Iris 是一個經典的「教學用」資料集，特點是：
1. **資料很乾淨** — 沒有缺失值、沒有雜訊
2. **特徵區分度高** — 三種花的特徵差異明顯
3. **資料量小** — 只有 150 筆，結構單純

在真實世界中，90% 以上就算很好了。很多實際問題（如醫療診斷、
詐騙偵測）能達到 80-85% 就已經非常實用。

不要被 Iris 的 100% 騙了，真實世界沒有這麼好的事！

</details>

---

## 完整程式碼（一次看完）

```python
"""
第 1 章：你的第一個機器學習模型
目標：用邏輯迴歸對鳶尾花資料集進行分類
"""

# ===== 1. 匯入套件 =====
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np

# ===== 2. 載入資料 =====
iris = load_iris()
X = iris.data       # 特徵矩陣 (150, 4)
y = iris.target     # 標籤向量 (150,)

print(f"資料集大小：{X.shape[0]} 筆，{X.shape[1]} 個特徵")
print(f"類別：{iris.target_names}")

# ===== 3. 分割資料 =====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
print(f"\n訓練集：{X_train.shape[0]} 筆")
print(f"測試集：{X_test.shape[0]} 筆")

# ===== 4. 訓練模型 =====
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

# ===== 5. 預測與評估 =====
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"\n測試集準確率：{accuracy:.2%}")
print(f"預測對了 {np.sum(y_pred == y_test)} / {len(y_test)} 筆")
```

---

## 本章全景圖

讓我們用一張圖總結這一章學到的所有概念：

```
┌─────────────────────────────────────────────────────────────┐
│                     機器學習全景圖                           │
│                                                             │
│  ┌─────────────┐          ┌──────────────────────────┐      │
│  │ 歷史資料     │─────────→│ 分割 train_test_split    │      │
│  │ (有標籤)     │          └──────────┬───────────────┘      │
│  └─────────────┘                     │                      │
│                            ┌─────────┴─────────┐            │
│                            ▼                   ▼            │
│                     ┌────────────┐      ┌────────────┐      │
│                     │  訓練集     │      │  測試集     │      │
│                     └─────┬──────┘      └──────┬─────┘      │
│                           │                    │            │
│                           ▼                    │            │
│                     ┌────────────┐              │            │
│                     │ model.fit()│              │            │
│                     │  訓練模型   │              │            │
│                     └─────┬──────┘              │            │
│                           │                    │            │
│                           ▼                    ▼            │
│                     ┌────────────┐      ┌────────────┐      │
│                     │  學到的模型 │─────→│ predict()  │      │
│                     └────────────┘      │  預測測試集 │      │
│                                         └──────┬─────┘      │
│                                                │            │
│                                                ▼            │
│                                         ┌────────────┐      │
│                                         │ 評估準確率  │      │
│                                         │ accuracy    │      │
│                                         └────────────┘      │
└─────────────────────────────────────────────────────────────┘
```

---

## 💡 重點觀念回顧

| 觀念 | 一句話解釋 |
|------|-----------|
| 機器學習 | 讓電腦從資料中自動學習規律，而不是人工寫規則 |
| 監督式學習 | 有標準答案（標籤）的學習方式 |
| 非監督式學習 | 沒有標準答案，讓電腦自己發現資料中的結構 |
| 特徵（Features） | 模型的輸入，用來描述資料的屬性 |
| 標籤（Labels） | 模型要預測的答案 |
| 訓練集 | 模型「學習」用的資料 |
| 測試集 | 評估模型「真實表現」的資料，模型從未見過 |
| 過擬合 | 模型「背答案」而不是「學會規律」 |
| `fit()` | 訓練模型（讓模型學習） |
| `predict()` | 用訓練好的模型做預測 |

---

## ⚠️ 常見陷阱

1. **拿全部資料訓練，然後用同一批資料測試**
   → 你測的是「背答案」的能力，不是真實表現。永遠要分割資料。

2. **忽略 random_state**
   → 結果無法重現，debug 時會抓狂。養成習慣，永遠設定。

3. **以為準確率高就是好模型**
   → 如果 95% 的郵件是正常的，一個「全部猜正常」的笨模型也有 95% 準確率。
   （後面章節會教更好的評估指標）

4. **忘記 `max_iter` 參數**
   → LogisticRegression 預設迭代次數可能不夠，會跳出警告。設 `max_iter=200` 以上。

5. **混淆「分類」和「迴歸」**
   → 預測類別用分類器，預測數值用迴歸器。用錯了模型不會報錯，但結果沒意義。

---

## 📝 課後練習

### 練習 1：改變分割比例

把 `test_size` 從 0.2 改成 0.3 和 0.5，觀察準確率的變化。
你覺得為什麼會有差異？

```python
for size in [0.2, 0.3, 0.5]:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=size, random_state=42
    )
    model = LogisticRegression(max_iter=200)
    model.fit(X_train, y_train)
    acc = accuracy_score(y_test, model.predict(X_test))
    print(f"test_size={size:.1f} → 訓練 {len(X_train)} 筆 / "
          f"測試 {len(X_test)} 筆 → 準確率 {acc:.2%}")
```

### 練習 2：觀察過擬合

試著用以下方式「製造」過擬合：用訓練集同時當測試集，看看分數有什麼不同。

```python
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

train_acc = accuracy_score(y_train, model.predict(X_train))
test_acc = accuracy_score(y_test, model.predict(X_test))

print(f"訓練集準確率：{train_acc:.2%}")
print(f"測試集準確率：{test_acc:.2%}")
print(f"差距：{train_acc - test_acc:.2%}")
```

如果差距很大，就是過擬合的徵兆。

### 練習 3：探索資料

用 pandas 載入 Iris 資料集，觀察每個特徵的基本統計量。

```python
import pandas as pd

df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target

print(df.describe())
print(df.groupby('species').mean())
```

思考：哪些特徵對區分不同品種最有用？

---

## 下一章預告

我們已經成功跑出了第一個 ML 模型。但你可能注意到了——

```python
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)
model.predict(X_test)
```

這三行程式碼的結構：**建立 → fit → predict**，背後其實藏著一個精心設計的哲學。

在第 2 章，我們會揭開 scikit-learn 的設計哲學——**Estimator API**。
你會發現，不管用什麼演算法，程式碼的結構幾乎一模一樣。
這不是巧合，而是刻意為之的優雅設計。

> **下一章：Scikit-learn 的設計哲學** →
