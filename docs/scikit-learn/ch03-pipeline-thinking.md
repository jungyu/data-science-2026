# ç¬¬ 3 ç« ï¼šPipeline æ€ç¶­

> **ã€ŒML ä¸æ˜¯æ¨¡å‹ï¼Œæ˜¯æµç¨‹ã€‚ã€** â€” è³‡æ–™ç§‘å­¸ç•Œçš„é‡‘ç§‘ç‰å¾‹

---

## ğŸ¯ æœ¬ç« ç›®æ¨™

è®€å®Œé€™ä¸€ç« ï¼Œä½ å°‡èƒ½å¤ ï¼š

- [ ] è§£é‡‹ä»€éº¼æ˜¯è³‡æ–™æ´©æ¼ï¼ˆData Leakageï¼‰ï¼Œä»¥åŠç‚ºä»€éº¼å®ƒé€™éº¼å±éšª
- [ ] ä½¿ç”¨ `StandardScaler` å’Œ `MinMaxScaler` æ­£ç¢ºåœ°æ¨™æº–åŒ–è³‡æ–™
- [ ] ç”¨ `sklearn.pipeline.Pipeline` æŠŠå‰è™•ç†å’Œæ¨¡å‹ä¸²æˆä¸€æ¢æµæ°´ç·š
- [ ] ç”¨ `ColumnTransformer` è™•ç†æ··åˆå‹æ…‹ï¼ˆæ•¸å€¼ + é¡åˆ¥ï¼‰çš„è³‡æ–™
- [ ] ç‰¢è¨˜é»ƒé‡‘æ³•å‰‡ï¼šã€Œå…ˆ splitï¼Œå† fitã€

---

## æ•…äº‹æ™‚é–“ï¼šä¸€å€‹å­¸ç”Ÿçš„æ‚²åŠ‡

å°é™³æ˜¯è³‡æ–™ç§‘å­¸æ‰€çš„ç¢©äºŒç”Ÿã€‚ä»–èŠ±äº†ä¸‰å€‹æœˆåšè«–æ–‡å¯¦é©—ï¼Œæ¨¡å‹æº–ç¢ºç‡é«˜é” 98.7%ã€‚
æŒ‡å°æ•™æˆçœ‹äº†éå¸¸èˆˆå¥®ï¼Œæº–å‚™æŠ•ç¨¿é ‚å°–æœƒè­°ã€‚

å£è©¦é‚£å¤©ï¼Œå£å§”å•äº†ä¸€å€‹å•é¡Œï¼š

> **ã€Œä½ çš„ StandardScaler æ˜¯åœ¨ä»€éº¼æ™‚å€™ fit çš„ï¼Ÿã€**

å°é™³å›ç­”ï¼šã€Œå°±â‹¯â‹¯åœ¨å…¨éƒ¨è³‡æ–™ä¸Šå•Šã€‚ã€

æ•™å®¤è£¡ä¸€ç‰‡æ²‰é»˜ã€‚å£å§”æ–äº†æ–é ­ã€‚

å°é™³çš„ 98.7% **å…¨æ˜¯å‡çš„**ã€‚

### ä»–çŠ¯äº†ä»€éº¼éŒ¯ï¼Ÿ

```python
# âŒ å°é™³çš„ç¨‹å¼ç¢¼ï¼ˆæœ‰åš´é‡çš„è³‡æ–™æ´©æ¼ï¼‰

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

# è¼‰å…¥è³‡æ–™
X, y = load_some_data()

# ğŸš¨ éŒ¯èª¤ï¼åœ¨å…¨éƒ¨è³‡æ–™ä¸Šåšæ¨™æº–åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)    # â† å•é¡Œåœ¨é€™è£¡ï¼

# ç„¶å¾Œæ‰åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# è¨“ç·´èˆ‡é æ¸¬
model = SVC()
model.fit(X_train, y_train)
print(f"æº–ç¢ºç‡ï¼š{model.score(X_test, y_test):.2%}")  # 98.7%ï¼ï¼ˆå‡çš„ï¼‰
```

### å•é¡Œå‡ºåœ¨å“ªè£¡ï¼Ÿ

```
å°é™³çš„åšæ³•ï¼ˆéŒ¯èª¤ï¼‰ï¼š

å…¨éƒ¨ 1000 ç­†è³‡æ–™
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ StandardScaler   â”‚ â† fit_transform åœ¨ã€Œå…¨éƒ¨ã€è³‡æ–™ä¸Š
â”‚ è¨ˆç®—å¹³å‡å€¼=50    â”‚    æ¸¬è©¦é›†çš„è³‡è¨Šä¹Ÿè¢«ã€Œçœ‹åˆ°ã€äº†ï¼
â”‚ è¨ˆç®—æ¨™æº–å·®=10    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  æ¨™æº–åŒ–å¾Œçš„è³‡æ–™
      â”‚
      â”œâ”€â”€â†’ è¨“ç·´é›† (800 ç­†)
      â”‚
      â””â”€â”€â†’ æ¸¬è©¦é›† (200 ç­†) â† å·²ç¶“è¢«ã€Œæ±™æŸ“ã€äº†ï¼
                               å› ç‚ºæ¨™æº–åŒ–çš„åƒæ•¸åŒ…å«äº†
                               æ¸¬è©¦é›†çš„çµ±è¨ˆé‡
```

```
æ­£ç¢ºçš„åšæ³•ï¼š

å…¨éƒ¨ 1000 ç­†è³‡æ–™
      â”‚
      â”œâ”€â”€â†’ è¨“ç·´é›† (800 ç­†)â”€â”€â†’ scaler.fit_transform() â† åªç”¨è¨“ç·´é›†ç®—çµ±è¨ˆé‡
      â”‚                             â”‚
      â”‚                             â–¼
      â”‚                       å¹³å‡å€¼=49.8
      â”‚                       æ¨™æº–å·®=10.2
      â”‚
      â””â”€â”€â†’ æ¸¬è©¦é›† (200 ç­†)â”€â”€â†’ scaler.transform()     â† ç”¨è¨“ç·´é›†çš„çµ±è¨ˆé‡è½‰æ›
                                                         ä¸åš fitï¼
```

---

## è³‡æ–™æ´©æ¼ï¼ˆData Leakageï¼‰

### ä»€éº¼æ˜¯è³‡æ–™æ´©æ¼ï¼Ÿ

> é¡æ¯”ï¼šè€ƒè©¦å‰å·çœ‹åˆ°äº†è€ƒå·ã€‚ä½ è€ƒäº† 100 åˆ†ï¼Œä½†é€™å€‹åˆ†æ•¸ä¸ä»£è¡¨ä½ çš„çœŸå¯¦èƒ½åŠ›ã€‚

**è³‡æ–™æ´©æ¼ = è¨“ç·´éç¨‹ä¸­ã€Œå·çœ‹ã€äº†æ¸¬è©¦é›†çš„è³‡è¨Šã€‚**

ä½ å¯èƒ½æ²’æœ‰ç›´æ¥çœ‹æ¸¬è©¦é›†çš„æ¨™ç±¤ï¼Œä½†åªè¦è¨“ç·´éç¨‹ä¸­ä½¿ç”¨äº†
ä»»ä½•ä¾†è‡ªæ¸¬è©¦é›†çš„çµ±è¨ˆè³‡è¨Šï¼ˆå¹³å‡å€¼ã€æ¨™æº–å·®ã€æœ€å¤§å€¼â‹¯â‹¯ï¼‰ï¼Œ
å°±å·²ç¶“æ§‹æˆæ´©æ¼ã€‚

### ç‚ºä»€éº¼é€™éº¼å±éšªï¼Ÿ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                          â”‚
â”‚  è³‡æ–™æ´©æ¼çš„å¾Œæœï¼š                                         â”‚
â”‚                                                          â”‚
â”‚  1. æ¸¬è©¦é›†åˆ†æ•¸è™›é«˜                                        â”‚
â”‚     â†’ ä½ ä»¥ç‚ºæ¨¡å‹å¾ˆå²å®³ï¼Œå…¶å¯¦åœ¨ä½œå¼Š                        â”‚
â”‚                                                          â”‚
â”‚  2. éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒå¾Œè¡¨ç¾æš´è·Œ                               â”‚
â”‚     â†’ çœŸå¯¦ä¸–ç•Œçš„è³‡æ–™æ²’æœ‰è¢«ã€Œå·çœ‹ã€çš„çµ±è¨ˆé‡                 â”‚
â”‚                                                          â”‚
â”‚  3. è«–æ–‡çµè«–ä¸å¯ä¿¡                                        â”‚
â”‚     â†’ å°é™³çš„ä¸‰å€‹æœˆç™½è²»äº†                                  â”‚
â”‚                                                          â”‚
â”‚  4. å•†æ¥­æ±ºç­–å¤±èª¤                                          â”‚
â”‚     â†’ éŠ€è¡Œä»¥ç‚ºæ¨¡å‹èƒ½æŠ“åˆ° 98% çš„å£å¸³ï¼Œ                     â”‚
â”‚       çµæœéƒ¨ç½²å¾Œåªæœ‰ 75%                                   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¡ é‡é»è§€å¿µ

> **é»ƒé‡‘æ³•å‰‡ï¼šå…ˆ splitï¼Œå† fitã€‚**
>
> ä»»ä½•æ¶‰åŠ `fit()` çš„æ“ä½œï¼ˆä¸ç®¡æ˜¯æ¨¡å‹é‚„æ˜¯å‰è™•ç†ï¼‰ï¼Œ
> éƒ½åªèƒ½åœ¨è¨“ç·´é›†ä¸Šåšã€‚æ¸¬è©¦é›†æ°¸é åªèƒ½ç”¨ `transform()`ã€‚

### ğŸ§  å‹•å‹•è…¦

ä»¥ä¸‹å“ªäº›æ“ä½œæœƒé€ æˆè³‡æ–™æ´©æ¼ï¼Ÿ

1. åœ¨å…¨éƒ¨è³‡æ–™ä¸Šè¨ˆç®—å¹³å‡å€¼ä¾†å¡«è£œç¼ºå¤±å€¼ï¼Œç„¶å¾Œæ‰ split
2. å…ˆ splitï¼Œç„¶å¾Œåœ¨è¨“ç·´é›†ä¸Š fit scalerï¼Œå† transform æ¸¬è©¦é›†
3. ç”¨å…¨éƒ¨è³‡æ–™åšç‰¹å¾µé¸æ“‡ï¼ˆæ‰¾å‡ºæœ€é‡è¦çš„ 10 å€‹ç‰¹å¾µï¼‰ï¼Œç„¶å¾Œæ‰ split
4. å…ˆ splitï¼Œç„¶å¾Œåªç”¨è¨“ç·´é›†åšç‰¹å¾µå·¥ç¨‹

<details>
<summary>é»æˆ‘çœ‹ç­”æ¡ˆ</summary>

1. **æœƒæ´©æ¼** â€” å¹³å‡å€¼åŒ…å«äº†æ¸¬è©¦é›†çš„è³‡è¨Š
2. **ä¸æœƒæ´©æ¼** â€” é€™æ˜¯æ­£ç¢ºåšæ³•
3. **æœƒæ´©æ¼** â€” ç‰¹å¾µé¸æ“‡ç”¨åˆ°äº†æ¸¬è©¦é›†çš„è³‡è¨Š
4. **ä¸æœƒæ´©æ¼** â€” é€™æ˜¯æ­£ç¢ºåšæ³•

**å£è¨£ï¼šä»»ä½• fit æ“ä½œï¼Œéƒ½ä¸èƒ½ç¢°æ¸¬è©¦é›†ã€‚**

</details>

---

## å‰è™•ç†ï¼šç‚ºä»€éº¼è¦æ¨™æº–åŒ–ï¼Ÿ

åœ¨é€²å…¥ Pipeline ä¹‹å‰ï¼Œå…ˆç†è§£ç‚ºä»€éº¼è³‡æ–™éœ€è¦å‰è™•ç†ã€‚

### ç‰¹å¾µå°ºåº¦ä¸åŒçš„å•é¡Œ

æƒ³åƒä½ æœ‰å…©å€‹ç‰¹å¾µï¼šã€Œå¹´æ”¶å…¥ã€å’Œã€Œå¹´é½¡ã€ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å®¢æˆ¶   â”‚  å¹´æ”¶å…¥ï¼ˆè¬å…ƒï¼‰  â”‚  å¹´é½¡ï¼ˆæ­²ï¼‰          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å°æ˜   â”‚  120            â”‚  35                  â”‚
â”‚  å°è¯   â”‚  45             â”‚  28                  â”‚
â”‚  å°ç¾   â”‚  200            â”‚  42                  â”‚
â”‚  å°å¼·   â”‚  80             â”‚  31                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å¹´æ”¶å…¥çš„ç¯„åœï¼š45 ~ 200
å¹´é½¡çš„ç¯„åœï¼š28 ~ 42

å•é¡Œï¼šå¹´æ”¶å…¥çš„ã€Œæ•¸å­—ã€é å¤§æ–¼å¹´é½¡ï¼Œ
     æŸäº›æ¼”ç®—æ³•æœƒä»¥ç‚ºå¹´æ”¶å…¥ã€Œæ›´é‡è¦ã€ï¼Œ
     åªå› ç‚ºå®ƒçš„æ•¸å­—æ¯”è¼ƒå¤§ã€‚
```

### StandardScalerï¼šæ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰

> é¡æ¯”ï¼šæŠŠæ‰€æœ‰äººçš„èº«é«˜ã€ŒæŒ‰ç…§å…¨ç­çš„å¹³å‡å’Œæ¨™æº–å·®ã€è½‰æˆçµ±ä¸€çš„åˆ»åº¦ã€‚

**å…¬å¼ï¼š** `z = (x - å¹³å‡å€¼) / æ¨™æº–å·®`

è½‰æ›å¾Œï¼Œæ¯å€‹ç‰¹å¾µçš„å¹³å‡å€¼ = 0ï¼Œæ¨™æº–å·® = 1ã€‚

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# æ­£ç¢ºåšæ³•ï¼šåªåœ¨è¨“ç·´é›†ä¸Š fit
scaler.fit(X_train)              # è¨ˆç®—è¨“ç·´é›†çš„å¹³å‡å€¼å’Œæ¨™æº–å·®

X_train_scaled = scaler.transform(X_train)  # ç”¨é€™äº›çµ±è¨ˆé‡è½‰æ›è¨“ç·´é›†
X_test_scaled = scaler.transform(X_test)    # ç”¨ã€ŒåŒæ¨£çš„ã€çµ±è¨ˆé‡è½‰æ›æ¸¬è©¦é›†

# æˆ–è€…è¨“ç·´é›†å¯ä»¥ç”¨ fit_transform ä¸€æ­¥åˆ°ä½
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)    # æ¸¬è©¦é›†åªèƒ½ transformï¼
```

```
è½‰æ›å‰ï¼š                           è½‰æ›å¾Œï¼š
å¹´æ”¶å…¥ï¼š[45, 80, 120, 200]        å¹´æ”¶å…¥ï¼š[-1.2, -0.4, 0.3, 1.3]
å¹´é½¡ï¼š  [28, 31, 35, 42]          å¹´é½¡ï¼š  [-1.1, -0.5, 0.2, 1.4]

ç¾åœ¨å…©å€‹ç‰¹å¾µçš„ã€Œå°ºåº¦ã€ä¸€æ¨£äº†ï¼
```

### MinMaxScalerï¼šæœ€å°æœ€å¤§ç¸®æ”¾

> é¡æ¯”ï¼šæŠŠæ‰€æœ‰åˆ†æ•¸ã€Œç­‰æ¯”ä¾‹ã€ç¸®æ”¾åˆ° 0ï½1 ä¹‹é–“ã€‚

**å…¬å¼ï¼š** `x_scaled = (x - æœ€å°å€¼) / (æœ€å¤§å€¼ - æœ€å°å€¼)`

è½‰æ›å¾Œï¼Œæ¯å€‹ç‰¹å¾µçš„æœ€å°å€¼ = 0ï¼Œæœ€å¤§å€¼ = 1ã€‚

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### ä»€éº¼æ™‚å€™ç”¨å“ªä¸€å€‹ï¼Ÿ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â”‚  StandardScaler        â”‚  MinMaxScaler        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è½‰æ›å¾Œç¯„åœ         â”‚  å¹³å‡=0, æ¨™æº–å·®=1      â”‚  [0, 1]              â”‚
â”‚ å°é›¢ç¾¤å€¼æ•æ„Ÿå—ï¼Ÿ   â”‚  è¼ƒä¸æ•æ„Ÿ              â”‚  éå¸¸æ•æ„Ÿ             â”‚
â”‚ é©åˆçš„æ¼”ç®—æ³•       â”‚  SVM, é‚è¼¯è¿´æ­¸,        â”‚  ç¥ç¶“ç¶²è·¯,            â”‚
â”‚                    â”‚  KNN, PCA              â”‚  å½±åƒè™•ç†             â”‚
â”‚ é©åˆçš„è³‡æ–™åˆ†å¸ƒ     â”‚  è¿‘ä¼¼å¸¸æ…‹åˆ†å¸ƒ           â”‚  æœ‰ç•Œçš„è³‡æ–™           â”‚
â”‚ å¸¸ç”¨ç¨‹åº¦           â”‚  æœ€å¸¸ç”¨ï¼ˆé è¨­é¦–é¸ï¼‰     â”‚  ç‰¹å®šå ´æ™¯ä½¿ç”¨         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âš ï¸ å¸¸è¦‹é™·é˜±

> **æ±ºç­–æ¨¹å’Œéš¨æ©Ÿæ£®æ—ä¸éœ€è¦æ¨™æº–åŒ–ï¼**
>
> æ¨¹æ¨¡å‹æ˜¯åŸºæ–¼ã€Œç‰¹å¾µçš„æ’åºã€ä¾†åˆ†å‰²ï¼Œä¸åœ¨ä¹çµ•å°å€¼å¤§å°ã€‚
> æ¨™æº–åŒ–å°å®ƒå€‘æ²’æœ‰å½±éŸ¿ï¼ˆä¹Ÿä¸æœƒæœ‰å®³ï¼Œåªæ˜¯å¤šæ­¤ä¸€èˆ‰ï¼‰ã€‚
>
> éœ€è¦æ¨™æº–åŒ–çš„æ¼”ç®—æ³•ï¼šSVMã€KNNã€é‚è¼¯è¿´æ­¸ã€PCAã€ç¥ç¶“ç¶²è·¯ã€‚
> ä¸éœ€è¦æ¨™æº–åŒ–çš„æ¼”ç®—æ³•ï¼šæ±ºç­–æ¨¹ã€éš¨æ©Ÿæ£®æ—ã€æ¢¯åº¦æå‡æ¨¹ã€‚

---

## Pipelineï¼šæŠŠæµç¨‹ä¸²èµ·ä¾†

### æ²’æœ‰ Pipeline çš„æ‰‹å‹•å¯«æ³•

```python
# æ­£ç¢ºä½†ç¹ç‘£çš„æ‰‹å‹•å¯«æ³•
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

# æ­¥é©Ÿ 1ï¼šæ¨™æº–åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)    # è¨“ç·´é›†ï¼šfit + transform
X_test_scaled = scaler.transform(X_test)           # æ¸¬è©¦é›†ï¼šåª transform

# æ­¥é©Ÿ 2ï¼šè¨“ç·´æ¨¡å‹
model = SVC()
model.fit(X_train_scaled, y_train)

# æ­¥é©Ÿ 3ï¼šè©•ä¼°
score = model.score(X_test_scaled, y_test)
print(f"æº–ç¢ºç‡ï¼š{score:.2%}")
```

é€™æ¨£å¯«æœ‰ä»€éº¼å•é¡Œï¼Ÿ

```
å•é¡Œ 1ï¼šå®¹æ˜“å¯«éŒ¯
  â†’ ä¸å°å¿ƒåœ¨æ¸¬è©¦é›†ä¸Šç”¨äº† fit_transform è€Œä¸æ˜¯ transform
  â†’ å¿˜è¨˜å°æ¸¬è©¦é›†åšæ¨™æº–åŒ–

å•é¡Œ 2ï¼šæ­¥é©Ÿå¤šæ™‚å¾ˆæ··äº‚
  â†’ å¦‚æœæœ‰ 5 å€‹å‰è™•ç†æ­¥é©Ÿ + 1 å€‹æ¨¡å‹ï¼Œè¦æ‰‹å‹•ç®¡ç† 6 å€‹ç‰©ä»¶

å•é¡Œ 3ï¼šå’Œäº¤å‰é©—è­‰ä¸ç›¸å®¹
  â†’ cross_val_score åªæ¥å—ä¸€å€‹æ¨¡å‹ç‰©ä»¶ï¼Œ
    ä½ çš„å‰è™•ç†æ­¥é©Ÿè¦æ€éº¼è¾¦ï¼Ÿ
```

### æœ‰ Pipeline çš„å„ªé›…å¯«æ³•

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

# å»ºç«‹ Pipelineï¼šä¸€æ¢æµæ°´ç·šæå®šæ‰€æœ‰æ­¥é©Ÿ
pipe = Pipeline([
    ('scaler', StandardScaler()),    # æ­¥é©Ÿ 1ï¼šæ¨™æº–åŒ–
    ('model', SVC())                 # æ­¥é©Ÿ 2ï¼šSVM åˆ†é¡
])

# è¨“ç·´ï¼šPipeline è‡ªå‹•è™•ç†æ‰€æœ‰æ­¥é©Ÿ
pipe.fit(X_train, y_train)
# å…§éƒ¨æµç¨‹ï¼š
# 1. scaler.fit_transform(X_train, y_train)
# 2. model.fit(X_train_scaled, y_train)

# é æ¸¬ï¼šPipeline è‡ªå‹•è™•ç†æ‰€æœ‰æ­¥é©Ÿ
score = pipe.score(X_test, y_test)
# å…§éƒ¨æµç¨‹ï¼š
# 1. scaler.transform(X_test)        â† è‡ªå‹•ç”¨ transformï¼Œä¸æ˜¯ fit_transformï¼
# 2. model.score(X_test_scaled, y_test)

print(f"æº–ç¢ºç‡ï¼š{score:.2%}")
```

### Pipeline çš„é‹ä½œæ©Ÿåˆ¶

```
pipe.fit(X_train, y_train) çš„å…§éƒ¨æµç¨‹ï¼š

X_train â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ StandardScaler â”‚     â”‚   SVC     â”‚
            â”‚ fit_transform()â”‚     â”‚  fit()    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            æ­¥é©Ÿ 1                 æ­¥é©Ÿ 2ï¼ˆæœ€å¾Œä¸€æ­¥ï¼‰

pipe.predict(X_test) çš„å…§éƒ¨æµç¨‹ï¼š

X_test  â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”€â”€â†’ é æ¸¬çµæœ
            â”‚ StandardScaler â”‚     â”‚   SVC     â”‚
            â”‚  transform()  â”‚     â”‚ predict() â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            æ­¥é©Ÿ 1                 æ­¥é©Ÿ 2

æ³¨æ„å·®ç•°ï¼š
  fit æ™‚ï¼šä¸­é–“æ­¥é©Ÿç”¨ fit_transform()
  predict æ™‚ï¼šä¸­é–“æ­¥é©Ÿç”¨ transform()ï¼ˆä¸ re-fitï¼ï¼‰

  Pipeline è‡ªå‹•å¹«ä½ è™•ç†äº†é€™å€‹å€åˆ¥ï¼Œä¸æœƒæ´©æ¼ï¼
```

### ğŸ’¡ é‡é»è§€å¿µ

> **Pipeline ä¸åªæ˜¯æ–¹ä¾¿ï¼Œå®ƒé‚„å¹«ä½ é˜²æ­¢è³‡æ–™æ´©æ¼ã€‚**
>
> æ‰‹å‹•å¯«å¾ˆå®¹æ˜“ä¸å°å¿ƒåœ¨æ¸¬è©¦é›†ä¸Š fitï¼ŒPipeline æœƒè‡ªå‹•åœ¨æ­£ç¢ºçš„
> æ™‚æ©Ÿç”¨ `fit_transform` æˆ– `transform`ã€‚

---

## Pipeline é€²éšç”¨æ³•

### å¤šæ­¥é©Ÿ Pipeline

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC

# ä¸‰æ­¥é©Ÿæµæ°´ç·š
pipe = Pipeline([
    ('scaler', StandardScaler()),     # æ­¥é©Ÿ 1ï¼šæ¨™æº–åŒ–
    ('pca', PCA(n_components=2)),     # æ­¥é©Ÿ 2ï¼šé™ç¶­åˆ° 2 ç¶­
    ('model', SVC(kernel='rbf'))      # æ­¥é©Ÿ 3ï¼šSVM åˆ†é¡
])

pipe.fit(X_train, y_train)
print(f"æº–ç¢ºç‡ï¼š{pipe.score(X_test, y_test):.2%}")

# å…§éƒ¨æµç¨‹ï¼ˆfit æ™‚ï¼‰ï¼š
# X_train â†’ StandardScaler.fit_transform â†’ PCA.fit_transform â†’ SVC.fit
#
# å…§éƒ¨æµç¨‹ï¼ˆpredict æ™‚ï¼‰ï¼š
# X_test â†’ StandardScaler.transform â†’ PCA.transform â†’ SVC.predict
```

### ç”¨ `make_pipeline` ç°¡åŒ–

å¦‚æœä½ æ‡¶å¾—å–åå­—ï¼Œå¯ä»¥ç”¨ `make_pipeline`ï¼š

```python
from sklearn.pipeline import make_pipeline

# è‡ªå‹•ç”¨é¡åˆ¥åç¨±ï¼ˆå°å¯«ï¼‰ç•¶æ­¥é©Ÿåç¨±
pipe = make_pipeline(
    StandardScaler(),
    PCA(n_components=2),
    SVC(kernel='rbf')
)

# æ­¥é©Ÿåç¨±è‡ªå‹•è¨­å®šç‚ºï¼š
# 'standardscaler', 'pca', 'svc'
print(pipe.named_steps)
```

### Pipeline + æ¨¡å‹æ¯”è¼ƒ

Pipeline è®“æ¨¡å‹æ¯”è¼ƒè®Šå¾—æ›´åŠ ä¹¾æ·¨ï¼š

```python
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# æ¯å€‹æ¨¡å‹éƒ½æœ‰è‡ªå·±çš„å®Œæ•´æµæ°´ç·š
pipelines = {
    "é‚è¼¯è¿´æ­¸": make_pipeline(StandardScaler(), LogisticRegression(max_iter=200)),
    "SVM":      make_pipeline(StandardScaler(), SVC()),
    "KNN":      make_pipeline(StandardScaler(), KNeighborsClassifier()),
}

print(f"{'æ¨¡å‹':<10} {'æº–ç¢ºç‡':>8}")
print("=" * 20)

for name, pipe in pipelines.items():
    pipe.fit(X_train, y_train)
    score = pipe.score(X_test, y_test)
    print(f"{name:<10} {score:>8.2%}")
```

---

## ColumnTransformerï¼šè™•ç†æ··åˆå‹è³‡æ–™

çœŸå¯¦ä¸–ç•Œçš„è³‡æ–™é€šå¸¸é•·é€™æ¨£ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å®¢æˆ¶   â”‚ å¹´æ”¶ â”‚ å¹´é½¡   â”‚ æ•™è‚²ç¨‹åº¦ â”‚ å±…ä½åŸå¸‚ â”‚
â”‚        â”‚ (æ•¸å€¼)â”‚ (æ•¸å€¼) â”‚ (é¡åˆ¥)   â”‚ (é¡åˆ¥)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å°æ˜   â”‚ 120  â”‚ 35     â”‚ ç¢©å£«     â”‚ å°åŒ—     â”‚
â”‚ å°è¯   â”‚ 45   â”‚ 28     â”‚ å­¸å£«     â”‚ é«˜é›„     â”‚
â”‚ å°ç¾   â”‚ 200  â”‚ 42     â”‚ åšå£«     â”‚ å°åŒ—     â”‚
â”‚ å°å¼·   â”‚ 80   â”‚ 31     â”‚ é«˜ä¸­     â”‚ å°ä¸­     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†‘      â†‘        â†‘          â†‘
       éœ€è¦æ¨™æº–åŒ–  éœ€è¦æ¨™æº–åŒ–  éœ€è¦ç·¨ç¢¼    éœ€è¦ç·¨ç¢¼

æ•¸å€¼ç‰¹å¾µå’Œé¡åˆ¥ç‰¹å¾µéœ€è¦ä¸åŒçš„å‰è™•ç†æ–¹å¼ï¼
```

### å•é¡Œï¼šä¸€å€‹ Scaler æä¸å®šæ‰€æœ‰æ¬„ä½

```python
# âŒ é€™è¡Œæœƒå‡ºéŒ¯æˆ–æ²’æ„ç¾©
scaler = StandardScaler()
scaler.fit_transform(X)   # å¦‚æœ X è£¡é¢æœ‰æ–‡å­—æ¬„ä½ï¼Œæœƒç›´æ¥å ±éŒ¯ï¼
```

### è§£æ³•ï¼šColumnTransformer

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# å®šç¾©ä¸åŒæ¬„ä½çš„è™•ç†æ–¹å¼
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['å¹´æ”¶', 'å¹´é½¡']),           # æ•¸å€¼æ¬„ä½ â†’ æ¨™æº–åŒ–
        ('cat', OneHotEncoder(), ['æ•™è‚²ç¨‹åº¦', 'å±…ä½åŸå¸‚']),     # é¡åˆ¥æ¬„ä½ â†’ ç¨ç†±ç·¨ç¢¼
    ]
)
```

### ColumnTransformer çš„é‹ä½œæ©Ÿåˆ¶

```
åŸå§‹è³‡æ–™ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¹´æ”¶ â”‚ å¹´é½¡ â”‚ æ•™è‚²ç¨‹åº¦ â”‚ å±…ä½åŸå¸‚ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 120  â”‚ 35   â”‚ ç¢©å£«     â”‚ å°åŒ—     â”‚
â”‚ 45   â”‚ 28   â”‚ å­¸å£«     â”‚ é«˜é›„     â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚      â”‚       â”‚          â”‚
    â–¼      â–¼       â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚StandardScalerâ”‚ â”‚          OneHotEncoder               â”‚
â”‚ æ¨™æº–åŒ–       â”‚ â”‚ ç¢©å£«â†’[0,1,0] å°åŒ—â†’[0,1,0]           â”‚
â”‚              â”‚ â”‚ å­¸å£«â†’[1,0,0] é«˜é›„â†’[1,0,0]           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚
       â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [-0.7, 0.5]  â”‚ â”‚ [0,1,0,  0,1,0]                     â”‚
â”‚ [ 1.2,-0.8]  â”‚ â”‚ [1,0,0,  1,0,0]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           åˆä½µæˆä¸€å€‹ç‰¹å¾µçŸ©é™£
  [-0.7, 0.5, 0, 1, 0, 0, 1, 0]
  [ 1.2,-0.8, 1, 0, 0, 1, 0, 0]
```

### å®Œæ•´ç¯„ä¾‹ï¼šColumnTransformer + Pipeline

```python
import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# ===== å»ºç«‹ç¯„ä¾‹è³‡æ–™ =====
data = pd.DataFrame({
    'å¹´æ”¶': [120, 45, 200, 80, 65, 150, 90, 55, 180, 70],
    'å¹´é½¡': [35, 28, 42, 31, 25, 38, 33, 27, 40, 29],
    'æ•™è‚²ç¨‹åº¦': ['ç¢©å£«', 'å­¸å£«', 'åšå£«', 'é«˜ä¸­', 'å­¸å£«',
                'ç¢©å£«', 'å­¸å£«', 'é«˜ä¸­', 'åšå£«', 'å­¸å£«'],
    'åŸå¸‚': ['å°åŒ—', 'é«˜é›„', 'å°åŒ—', 'å°ä¸­', 'é«˜é›„',
            'å°åŒ—', 'å°ä¸­', 'é«˜é›„', 'å°åŒ—', 'å°ä¸­'],
    'æ ¸å‡†': [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]
})

X = data.drop('æ ¸å‡†', axis=1)
y = data['æ ¸å‡†']

# ===== å®šç¾©æ¬„ä½ =====
numeric_features = ['å¹´æ”¶', 'å¹´é½¡']
categorical_features = ['æ•™è‚²ç¨‹åº¦', 'åŸå¸‚']

# ===== å»ºç«‹å‰è™•ç†å™¨ =====
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
    ]
)

# ===== å»ºç«‹å®Œæ•´ Pipeline =====
full_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=200)),
])

# ===== åˆ†å‰²ã€è¨“ç·´ã€è©•ä¼° =====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

full_pipeline.fit(X_train, y_train)
print(f"æº–ç¢ºç‡ï¼š{full_pipeline.score(X_test, y_test):.2%}")

# ===== é æ¸¬æ–°å®¢æˆ¶ =====
new_customer = pd.DataFrame({
    'å¹´æ”¶': [100],
    'å¹´é½¡': [30],
    'æ•™è‚²ç¨‹åº¦': ['ç¢©å£«'],
    'åŸå¸‚': ['å°åŒ—'],
})

prediction = full_pipeline.predict(new_customer)
print(f"æ–°å®¢æˆ¶é æ¸¬ï¼š{'æ ¸å‡†' if prediction[0] == 1 else 'æ‹’çµ•'}")
```

### â“ æ²’æœ‰ç¬¨å•é¡Œ

**Qï¼šOneHotEncoder çš„ `handle_unknown='ignore'` æ˜¯ä»€éº¼æ„æ€ï¼Ÿ**

Aï¼šå¦‚æœé æ¸¬æ™‚é‡åˆ°è¨“ç·´æ™‚æ²’è¦‹éçš„é¡åˆ¥ï¼ˆä¾‹å¦‚è¨“ç·´æ™‚æ²’æœ‰ã€Œæ–°ç«¹ã€é€™å€‹åŸå¸‚ï¼‰ï¼Œ
`ignore` æœƒæŠŠé‚£å€‹é¡åˆ¥çš„æ‰€æœ‰ one-hot æ¬„ä½è¨­ç‚º 0ï¼Œè€Œä¸æ˜¯å ±éŒ¯ã€‚
åœ¨çœŸå¯¦ä¸–ç•Œä¸­é€™å¾ˆå¸¸è¦‹ã€‚

**Qï¼šColumnTransformer çš„ `remainder` åƒæ•¸æ˜¯ä»€éº¼ï¼Ÿ**

Aï¼šé è¨­æ˜¯ `'drop'`â€”â€”æ²’æœ‰è¢«æŒ‡å®šè™•ç†çš„æ¬„ä½æœƒè¢«ä¸Ÿæ‰ã€‚
å¦‚æœä½ æƒ³ä¿ç•™å®ƒå€‘ä¸åšä»»ä½•è™•ç†ï¼Œå¯ä»¥è¨­ `remainder='passthrough'`ã€‚

**Qï¼šPipeline è£¡çš„æ­¥é©Ÿåç¨±ï¼ˆå¦‚ `'preprocessor'`ï¼‰æœ‰ä»€éº¼ç”¨ï¼Ÿ**

Aï¼šåœ¨è¶…åƒæ•¸æœå°‹æ™‚æœƒç”¨åˆ°ã€‚ä¾‹å¦‚ä½ è¦èª¿ `classifier` çš„ `C` åƒæ•¸ï¼Œ
å¯ä»¥å¯« `param_grid = {'classifier__C': [0.1, 1, 10]}`ã€‚
é›™åº•ç·š `__` è¡¨ç¤ºã€Œé€²å…¥é‚£å€‹æ­¥é©Ÿè£¡é¢ã€ã€‚

---

## Pipeline çš„å¥½è™•ç¸½çµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Pipeline çš„äº”å¤§å¥½è™•                           â”‚
â”‚                                                             â”‚
â”‚  1. é˜²æ­¢è³‡æ–™æ´©æ¼                                             â”‚
â”‚     â†’ fit å’Œ transform çš„æ™‚æ©Ÿè‡ªå‹•è™•ç†æ­£ç¢º                    â”‚
â”‚                                                             â”‚
â”‚  2. ç¨‹å¼ç¢¼æ›´ä¹¾æ·¨                                             â”‚
â”‚     â†’ ä¸€å€‹ç‰©ä»¶æå®šæ‰€æœ‰æ­¥é©Ÿï¼Œä¸ç”¨ç®¡ç†ä¸€å †ä¸­é–“è®Šæ•¸             â”‚
â”‚                                                             â”‚
â”‚  3. å’Œäº¤å‰é©—è­‰ç›¸å®¹                                           â”‚
â”‚     â†’ cross_val_score(pipe, X, y) ç›´æ¥ç”¨                    â”‚
â”‚                                                             â”‚
â”‚  4. æ–¹ä¾¿éƒ¨ç½²                                                 â”‚
â”‚     â†’ ç”¨ joblib.dump(pipe) å­˜ä¸‹æ•´æ¢æµæ°´ç·š                    â”‚
â”‚     â†’ éƒ¨ç½²æ™‚ joblib.load(pipe) å°±èƒ½ç›´æ¥é æ¸¬                  â”‚
â”‚                                                             â”‚
â”‚  5. è¶…åƒæ•¸æœå°‹                                               â”‚
â”‚     â†’ GridSearchCV å¯ä»¥åŒæ™‚æœå°‹å‰è™•ç†å’Œæ¨¡å‹çš„è¶…åƒæ•¸           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äº¤å‰é©—è­‰ + Pipeline

Pipeline çœŸæ­£ç™¼å¨çš„åœ°æ–¹æ˜¯å’Œäº¤å‰é©—è­‰æ­é…ï¼š

```python
from sklearn.model_selection import cross_val_score

pipe = make_pipeline(
    StandardScaler(),
    SVC()
)

# 5-fold äº¤å‰é©—è­‰
# æ¯ä¸€æŠ˜éƒ½æœƒæ­£ç¢ºåœ°ï¼š
#   1. åœ¨è©²æŠ˜çš„è¨“ç·´é›†ä¸Š fit scaler
#   2. åœ¨è©²æŠ˜çš„æ¸¬è©¦é›†ä¸Š transformï¼ˆä¸ re-fitï¼‰
#   3. è¨“ç·´ SVC ä¸¦è©•ä¼°
scores = cross_val_score(pipe, iris.data, iris.target, cv=5)

print(f"æ¯æŠ˜æº–ç¢ºç‡ï¼š{scores}")
print(f"å¹³å‡æº–ç¢ºç‡ï¼š{scores.mean():.2%} (+/- {scores.std():.2%})")
```

```
å¦‚æœä½ ä¸ç”¨ Pipelineï¼Œæ‰‹å‹•åšäº¤å‰é©—è­‰ï¼š

ç¬¬ 1 æŠ˜ï¼š
  scaler.fit(X_fold1_train)     â† æ‰‹å‹• fit
  scaler.transform(X_fold1_test) â† æ‰‹å‹• transform
  model.fit(...)                  â† æ‰‹å‹• fit
  model.score(...)                â† æ‰‹å‹• score

ç¬¬ 2 æŠ˜ï¼š
  scaler.fit(X_fold2_train)     â† åˆè¦æ‰‹å‹• fitï¼ˆä¸åŒçš„è¨“ç·´é›†ï¼ï¼‰
  scaler.transform(X_fold2_test)
  model.fit(...)
  model.score(...)

...é‡è¤‡ 5 æ¬¡ï¼Œéå¸¸å®¹æ˜“å¯«éŒ¯ï¼

ç”¨ Pipelineï¼šä¸€è¡Œ cross_val_score æå®šï¼Œè€Œä¸”ä¿è­‰æ­£ç¢ºã€‚
```

---

## å®Œæ•´ç¯„ä¾‹ï¼šå¾é ­åˆ°å°¾çš„æ­£ç¢ºæµç¨‹

```python
"""
ç¬¬ 3 ç« ï¼šPipeline å®Œæ•´ç¤ºç¯„
å±•ç¤ºæ­£ç¢ºçš„ ML å·¥ä½œæµç¨‹
"""

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
import numpy as np

# ===== è¼‰å…¥è³‡æ–™ =====
iris = load_iris()
X, y = iris.data, iris.target

# ===== åˆ†å‰²è³‡æ–™ï¼ˆç¬¬ä¸€æ­¥æ°¸é æ˜¯ splitï¼ï¼‰=====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ===== å®šç¾© Pipelines =====
pipelines = {
    "LR + Scaling":  make_pipeline(StandardScaler(), LogisticRegression(max_iter=200)),
    "SVM + Scaling": make_pipeline(StandardScaler(), SVC()),
    "KNN + Scaling": make_pipeline(StandardScaler(), KNeighborsClassifier()),
    "SVM (no scale)": SVC(),               # å°ç…§çµ„ï¼šä¸æ¨™æº–åŒ–çš„ SVM
    "KNN (no scale)": KNeighborsClassifier(), # å°ç…§çµ„ï¼šä¸æ¨™æº–åŒ–çš„ KNN
}

# ===== äº¤å‰é©—è­‰æ¯”è¼ƒ =====
print("=" * 60)
print(f"{'æ¨¡å‹':<20} {'CV å¹³å‡':>10} {'CV æ¨™æº–å·®':>10} {'æ¸¬è©¦é›†':>10}")
print("=" * 60)

for name, pipe in pipelines.items():
    # äº¤å‰é©—è­‰ï¼ˆåªåœ¨è¨“ç·´é›†ä¸Šåšï¼ï¼‰
    cv_scores = cross_val_score(pipe, X_train, y_train, cv=5)

    # æœ€çµ‚è©•ä¼°ï¼ˆåœ¨æ¸¬è©¦é›†ä¸Šï¼‰
    pipe.fit(X_train, y_train)
    test_score = pipe.score(X_test, y_test)

    print(f"{name:<20} {cv_scores.mean():>10.2%} "
          f"{cv_scores.std():>10.2%} {test_score:>10.2%}")

print("=" * 60)
```

---

## æœ¬ç« å…¨æ™¯åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ­£ç¢ºçš„ ML æµç¨‹                             â”‚
â”‚                                                             â”‚
â”‚  åŸå§‹è³‡æ–™                                                    â”‚
â”‚    â”‚                                                        â”‚
â”‚    â–¼                                                        â”‚
â”‚  train_test_split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¸¬è©¦é›†ï¼ˆå…ˆæ”¾ä¸€é‚Šï¼Œæœ€å¾Œæ‰ç”¨ï¼‰   â”‚
â”‚    â”‚                                                        â”‚
â”‚    â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚                                     â”‚                    â”‚
â”‚  â”‚  ColumnTransformer                  â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â”‚
â”‚  â”‚  â”‚ æ•¸å€¼æ¬„ä½     â”‚ é¡åˆ¥æ¬„ä½       â”‚  â”‚                    â”‚
â”‚  â”‚  â”‚ StandardScaleâ”‚ OneHotEncoder  â”‚  â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                    â”‚
â”‚  â”‚           â”‚                         â”‚                    â”‚
â”‚  â”‚           â–¼                         â”‚                    â”‚
â”‚  â”‚     åˆä½µå¾Œçš„ç‰¹å¾µ                     â”‚                    â”‚
â”‚  â”‚           â”‚                         â”‚                    â”‚
â”‚  â”‚           â–¼                         â”‚                    â”‚
â”‚  â”‚     æ¨¡å‹ï¼ˆClassifier/Regressorï¼‰    â”‚                    â”‚
â”‚  â”‚                                     â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚    â”‚                                                        â”‚
â”‚    â”œâ”€â”€â†’ cross_val_scoreï¼ˆäº¤å‰é©—è­‰ï¼Œé¸æ¨¡å‹ï¼‰                  â”‚
â”‚    â”‚                                                        â”‚
â”‚    â”œâ”€â”€â†’ fitï¼ˆæœ€çµ‚è¨“ç·´ï¼‰                                      â”‚
â”‚    â”‚                                                        â”‚
â”‚    â””â”€â”€â†’ scoreï¼ˆåœ¨æ¸¬è©¦é›†ä¸Šæœ€çµ‚è©•ä¼°ï¼‰                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ å¸¸è¦‹é™·é˜±

1. **å…ˆæ¨™æº–åŒ–å†åˆ†å‰²ï¼ˆè³‡æ–™æ´©æ¼ï¼ï¼‰**
   â†’ æ°¸é å…ˆ `train_test_split`ï¼Œå†åœ¨è¨“ç·´é›†ä¸Šåšä»»ä½• `fit` æ“ä½œã€‚

2. **æ¸¬è©¦é›†ä¸Šç”¨äº† `fit_transform()` è€Œä¸æ˜¯ `transform()`**
   â†’ æ¸¬è©¦é›†åªèƒ½ç”¨ `transform()`ã€‚Pipeline æœƒè‡ªå‹•è™•ç†ï¼Œä½†æ‰‹å‹•å¯«è¦å°å¿ƒã€‚

3. **å¿˜è¨˜å°æ¸¬è©¦é›†åšå‰è™•ç†**
   â†’ æ¨¡å‹è¨“ç·´æ™‚çœ‹åˆ°çš„æ˜¯æ¨™æº–åŒ–å¾Œçš„è³‡æ–™ï¼Œæ¸¬è©¦æ™‚ä¹Ÿè¦æ¨™æº–åŒ–ã€‚
   å¦å‰‡å°ºåº¦ä¸åŒï¼Œé æ¸¬çµæœæ¯«ç„¡æ„ç¾©ã€‚

4. **Pipeline æ­¥é©Ÿé †åºæéŒ¯**
   â†’ é€šå¸¸æ˜¯ï¼šç¼ºå¤±å€¼è™•ç† â†’ ç·¨ç¢¼ â†’ æ¨™æº–åŒ– â†’ æ¨¡å‹ã€‚
   é †åºä¸åŒå¯èƒ½å°è‡´éŒ¯èª¤æˆ–æ•ˆæœä¸ä½³ã€‚

5. **å¿˜è¨˜ ColumnTransformer çš„ `remainder` åƒæ•¸**
   â†’ é è¨­æ˜¯ `'drop'`ï¼Œæ²’æŒ‡å®šè™•ç†çš„æ¬„ä½æœƒæ¶ˆå¤±ã€‚
   å¦‚æœè¦ä¿ç•™ï¼Œè«‹è¨­ `remainder='passthrough'`ã€‚

6. **ä»¥ç‚ºæ‰€æœ‰æ¼”ç®—æ³•éƒ½éœ€è¦æ¨™æº–åŒ–**
   â†’ æ¨¹æ¨¡å‹ï¼ˆæ±ºç­–æ¨¹ã€éš¨æ©Ÿæ£®æ—ã€XGBoostï¼‰ä¸éœ€è¦ã€‚
   ä½†æ”¾åœ¨ Pipeline è£¡ä¹Ÿä¸æœƒæœ‰å®³ï¼Œåªæ˜¯å¤šèŠ±ä¸€é»è¨ˆç®—æ™‚é–“ã€‚

---

## ğŸ’¡ é‡é»è§€å¿µå›é¡§

| è§€å¿µ | ä¸€å¥è©±è§£é‡‹ |
|------|-----------|
| è³‡æ–™æ´©æ¼ | è¨“ç·´éç¨‹ä¸­ã€Œå·çœ‹ã€äº†æ¸¬è©¦é›†çš„è³‡è¨Šï¼Œå°è‡´åˆ†æ•¸è™›é«˜ |
| é»ƒé‡‘æ³•å‰‡ | å…ˆ splitï¼Œå† fitã€‚ä»»ä½• fit æ“ä½œåªèƒ½ç¢°è¨“ç·´é›† |
| StandardScaler | æŠŠè³‡æ–™è½‰æˆå¹³å‡=0ã€æ¨™æº–å·®=1 çš„æ¨™æº–åˆ†æ•¸ |
| MinMaxScaler | æŠŠè³‡æ–™ç¸®æ”¾åˆ° [0, 1] çš„ç¯„åœ |
| Pipeline | æŠŠå‰è™•ç†å’Œæ¨¡å‹ä¸²æˆä¸€æ¢æµæ°´ç·šï¼Œè‡ªå‹•è™•ç† fit/transform |
| ColumnTransformer | å°ä¸åŒæ¬„ä½åšä¸åŒçš„å‰è™•ç† |
| OneHotEncoder | æŠŠé¡åˆ¥ç‰¹å¾µè½‰æˆ 0/1 çš„äºŒå…ƒå‘é‡ |
| `fit_transform()` | åªåœ¨è¨“ç·´é›†ä¸Šç”¨ |
| `transform()` | åœ¨æ¸¬è©¦é›†ä¸Šç”¨ï¼ˆä¸ re-fitï¼‰ |
| cross_val_score | äº¤å‰é©—è­‰ï¼Œå’Œ Pipeline æ­é…ä½¿ç”¨æœ€å®‰å…¨ |

---

## ğŸ“ èª²å¾Œç·´ç¿’

### ç·´ç¿’ 1ï¼šæŠ“è³‡æ–™æ´©æ¼ Bug

ä»¥ä¸‹ç¨‹å¼ç¢¼æœ‰è³‡æ–™æ´©æ¼ã€‚è«‹æ‰¾å‡ºå•é¡Œä¸¦ä¿®æ­£ã€‚

```python
# ğŸ› æœ‰ Bug çš„ç¨‹å¼ç¢¼
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

iris = load_iris()
X, y = iris.data, iris.target

# å‰è™•ç†
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X_pca, y, test_size=0.2, random_state=42
)

# è¨“ç·´èˆ‡è©•ä¼°
model = SVC()
model.fit(X_train, y_train)
print(f"æº–ç¢ºç‡ï¼š{model.score(X_test, y_test):.2%}")
```

<details>
<summary>é»æˆ‘çœ‹æç¤º</summary>

å•é¡Œï¼šStandardScaler å’Œ PCA éƒ½åœ¨ split ä¹‹å‰åšäº† `fit_transform`ã€‚

ä¿®æ­£æ–¹æ³•æœ‰å…©ç¨®ï¼š
1. å…ˆ splitï¼Œå†æ‰‹å‹•åš fit_transformï¼ˆè¨“ç·´é›†ï¼‰å’Œ transformï¼ˆæ¸¬è©¦é›†ï¼‰
2. ç”¨ Pipelineï¼ˆæ¨è–¦ï¼ï¼‰

</details>

<details>
<summary>é»æˆ‘çœ‹ç­”æ¡ˆ</summary>

```python
# âœ… ä¿®æ­£å¾Œçš„ç¨‹å¼ç¢¼ï¼ˆç”¨ Pipelineï¼‰
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

iris = load_iris()
X, y = iris.data, iris.target

# å…ˆåˆ†å‰²ï¼
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ç”¨ Pipeline ä¸²èµ·ä¾†
pipe = make_pipeline(
    StandardScaler(),
    PCA(n_components=2),
    SVC()
)

pipe.fit(X_train, y_train)
print(f"æº–ç¢ºç‡ï¼š{pipe.score(X_test, y_test):.2%}")
```

</details>

### ç·´ç¿’ 2ï¼šå»ºç«‹æ··åˆè³‡æ–™ Pipeline

ä½¿ç”¨ä»¥ä¸‹è³‡æ–™ï¼Œå»ºç«‹ä¸€å€‹åŒ…å« ColumnTransformer çš„å®Œæ•´ Pipelineï¼š

```python
import pandas as pd

# å»ºç«‹è³‡æ–™
df = pd.DataFrame({
    'age': [25, 30, 35, 40, 45, 50, 55, 60, 28, 33],
    'income': [30, 50, 70, 90, 80, 100, 120, 95, 40, 60],
    'education': ['é«˜ä¸­', 'å­¸å£«', 'ç¢©å£«', 'åšå£«', 'å­¸å£«',
                  'ç¢©å£«', 'åšå£«', 'ç¢©å£«', 'é«˜ä¸­', 'å­¸å£«'],
    'approved': [0, 0, 1, 1, 1, 1, 1, 1, 0, 0]
})

# ä½ çš„ä»»å‹™ï¼š
# 1. åˆ†å‡º X å’Œ y
# 2. train_test_split
# 3. å»ºç«‹ ColumnTransformerï¼ˆæ•¸å€¼æ¨™æº–åŒ– + é¡åˆ¥ç·¨ç¢¼ï¼‰
# 4. å»ºç«‹åŒ…å«å‰è™•ç†å’Œåˆ†é¡å™¨çš„ Pipeline
# 5. è¨“ç·´å’Œè©•ä¼°
```

### ç·´ç¿’ 3ï¼šPipeline å’Œäº¤å‰é©—è­‰

ç”¨ Iris è³‡æ–™é›†ï¼Œæ¯”è¼ƒä»¥ä¸‹ä¸‰å€‹ Pipeline çš„äº¤å‰é©—è­‰åˆ†æ•¸ï¼š

```python
# Pipeline 1: StandardScaler + LogisticRegression
# Pipeline 2: MinMaxScaler + LogisticRegression
# Pipeline 3: ä¸åšæ¨™æº–åŒ– + LogisticRegression

# æç¤ºï¼š
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LogisticRegression

# ä½ çš„ç¨‹å¼ç¢¼åœ¨é€™è£¡...
```

è§€å¯Ÿï¼šæ¨™æº–åŒ–å°é‚è¼¯è¿´æ­¸çš„è¡¨ç¾æœ‰å½±éŸ¿å—ï¼Ÿ

---

## ä¸‹ä¸€ç« é å‘Š

ä½ å·²ç¶“å­¸æœƒäº† ML çš„æ­£ç¢ºæµç¨‹ï¼šåˆ†å‰² â†’ å‰è™•ç† â†’ æ¨¡å‹ â†’ è©•ä¼°ã€‚

ä½†ä½ å¯èƒ½æœƒå•ï¼šã€Œæº–ç¢ºç‡ 95%ï¼Œå°±ä»£è¡¨æ¨¡å‹çœŸçš„å¥½å—ï¼Ÿã€

ç­”æ¡ˆæ˜¯ï¼š**ä¸ä¸€å®šã€‚**

å¦‚æœ 1000 å°éƒµä»¶è£¡æœ‰ 950 å°æ˜¯æ­£å¸¸çš„ï¼Œä¸€å€‹ã€Œå…¨éƒ¨çŒœæ­£å¸¸ã€çš„ç¬¨æ¨¡å‹
ä¹Ÿæœ‰ 95% æº–ç¢ºç‡ã€‚æˆ‘å€‘éœ€è¦æ›´å¥½çš„è©•ä¼°æ–¹æ³•ã€‚

> **ä¸‹ä¸€ç« ï¼šæ¨¡å‹è©•ä¼° â€” æº–ç¢ºç‡ä¹‹å¤–çš„ä¸–ç•Œ** â†’
