# ç¬¬åä¸ƒç« ï¼šå°ˆæ¡ˆè£½ä½œèˆ‡æœŸæœ«ç™¼è¡¨ â€” æŠŠä¸€åˆ‡ä¸²èµ·ä¾†

> ã€Œå­¸æ­¦åŠŸè¦å¯¦æˆ°ï¼Œå­¸ ML è¦åšå°ˆæ¡ˆã€‚ã€

```
ç¬¬ 1-16 ç« çš„ä½ ï¼š                  åšå®Œå°ˆæ¡ˆçš„ä½ ï¼š

  "æˆ‘æ‡‚ Random Forest"              "æˆ‘çŸ¥é“ä»€éº¼æ™‚å€™è©²ç”¨
   "æˆ‘æœƒèª¿è¶…åƒæ•¸"                     Random Forestï¼Œ
   "æˆ‘çŸ¥é“ cross validation"          ä»€éº¼æ™‚å€™ä¸è©²ç”¨ï¼Œ
                                      ä»¥åŠæ€éº¼èªªæœè€é—†
                                      ç‚ºä»€éº¼è¦ç”¨å®ƒã€‚"

   çŸ¥è­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º èƒ½åŠ›
```

---

## ğŸ¯ æœ¬ç« ç›®æ¨™

å®Œæˆæœ¬ç« å¾Œï¼Œä½ å°‡èƒ½å¤ ï¼š

1. å®šç¾©ä¸€å€‹æ˜ç¢ºçš„æ©Ÿå™¨å­¸ç¿’å•é¡Œ
2. å®Œæˆç«¯åˆ°ç«¯çš„ ML å°ˆæ¡ˆæµç¨‹
3. æ¯”è¼ƒè‡³å°‘ 3 ç¨®æ¨¡å‹ä¸¦åˆç†è§£é‡‹é¸æ“‡
4. ä½¿ç”¨ cross validation åšå¯é çš„æ¨¡å‹è©•ä¼°
5. é€²è¡Œ bias-variance åˆ†æ
6. æ’°å¯«å°ˆæ¥­çš„è©•ä¼°å ±å‘Šèˆ‡å•†æ¥­å»ºè­°
7. æº–å‚™æœŸæœ«ç™¼è¡¨æ‰€éœ€çš„å…¨éƒ¨äº¤ä»˜é …ç›®

---

## 17.1 å°ˆæ¡ˆè¦æ±‚ç¸½è¦½

### ä¸ƒå¤§æ ¸å¿ƒè¦ç´ 

```
å®Œæ•´ ML å°ˆæ¡ˆçš„ä¸ƒå¤§è¦ç´ ï¼š

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                            â”‚
  â”‚  1. å•é¡Œå®šç¾©          â† æœ€é‡è¦ï¼Œå»æœ€å¸¸è¢«å¿½ç•¥ â”‚
  â”‚     â†“                                      â”‚
  â”‚  2. è³‡æ–™è™•ç†                                â”‚
  â”‚     â†“                                      â”‚
  â”‚  3. æ¨¡å‹æ¯”è¼ƒï¼ˆè‡³å°‘ 3 ç¨®ï¼‰                    â”‚
  â”‚     â†“                                      â”‚
  â”‚  4. Cross Validation                       â”‚
  â”‚     â†“                                      â”‚
  â”‚  5. Bias-Variance åˆ†æ                     â”‚
  â”‚     â†“                                      â”‚
  â”‚  6. è©•ä¼°åˆ†æ                                â”‚
  â”‚     â†“                                      â”‚
  â”‚  7. å•†æ¥­å»ºè­°                                â”‚
  â”‚                                            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 17.2 å•é¡Œå®šç¾©ï¼šä½ åœ¨è§£æ±ºä»€éº¼ï¼Ÿ

### å¥½çš„å•é¡Œå®šç¾© vs å£çš„å•é¡Œå®šç¾©

```
âŒ å£çš„å•é¡Œå®šç¾©ï¼š
"æˆ‘è¦ç”¨æ©Ÿå™¨å­¸ç¿’é æ¸¬æ±è¥¿"
"æˆ‘è¦åšä¸€å€‹å¾ˆæº–çš„æ¨¡å‹"
"æˆ‘æ‰¾äº†ä¸€å€‹ Kaggle è³‡æ–™é›†"

âœ… å¥½çš„å•é¡Œå®šç¾©ï¼š
"é›»å•†å…¬å¸æƒ³é æ¸¬å“ªäº›å®¢æˆ¶åœ¨æœªä¾† 30 å¤©å…§
 æœƒæµå¤±ï¼ˆä¸å†è³¼è²·ï¼‰ï¼Œä»¥ä¾¿æå‰ä»‹å…¥æŒ½ç•™ã€‚
 ç›®æ¨™ï¼šè­˜åˆ¥å‡ºè‡³å°‘ 80% å³å°‡æµå¤±çš„å®¢æˆ¶
 ï¼ˆrecall â‰¥ 0.8ï¼‰ï¼ŒåŒæ™‚æ§åˆ¶èª¤å ±ç‡
 ï¼ˆprecision â‰¥ 0.5ï¼‰ä»¥å…æµªè²»è¡ŒéŠ·è³‡æºã€‚"
```

### å•é¡Œå®šç¾©æ¨¡æ¿

```
+----------------------------------------------------------+
|  å•é¡Œå®šç¾©æ¨¡æ¿                                              |
+----------------------------------------------------------+
|                                                            |
|  1. æ¥­å‹™èƒŒæ™¯ï¼š                                             |
|     å…¬å¸/çµ„ç¹”é¢è‡¨ä»€éº¼å•é¡Œï¼Ÿ                                |
|     ç‚ºä»€éº¼éœ€è¦ ML ä¾†è§£æ±ºï¼Ÿ                                 |
|     _____________________________________________          |
|                                                            |
|  2. ç›®æ¨™å®šç¾©ï¼š                                             |
|     é æ¸¬ä»€éº¼ï¼Ÿï¼ˆy æ˜¯ä»€éº¼ï¼Ÿï¼‰                               |
|     åˆ†é¡é‚„æ˜¯å›æ­¸ï¼Ÿ                                         |
|     _____________________________________________          |
|                                                            |
|  3. æˆåŠŸæ¨™æº–ï¼š                                             |
|     ç”¨ä»€éº¼æŒ‡æ¨™è¡¡é‡æˆåŠŸï¼Ÿ                                   |
|     ç›®æ¨™å€¼æ˜¯å¤šå°‘ï¼Ÿç‚ºä»€éº¼ï¼Ÿ                                 |
|     _____________________________________________          |
|                                                            |
|  4. é™åˆ¶æ¢ä»¶ï¼š                                             |
|     æ¨¡å‹éœ€è¦å¯è§£é‡‹å—ï¼Ÿ                                     |
|     æœ‰æ™‚é–“/è¨ˆç®—è³‡æºé™åˆ¶å—ï¼Ÿ                                |
|     æœ‰å…¬å¹³æ€§/å€«ç†è€ƒé‡å—ï¼Ÿ                                  |
|     _____________________________________________          |
|                                                            |
|  5. å½±éŸ¿åˆ†æï¼š                                             |
|     False Positive çš„ä»£åƒ¹æ˜¯ä»€éº¼ï¼Ÿ                          |
|     False Negative çš„ä»£åƒ¹æ˜¯ä»€éº¼ï¼Ÿ                          |
|     å“ªå€‹æ›´åš´é‡ï¼Ÿ                                           |
|     _____________________________________________          |
|                                                            |
+----------------------------------------------------------+
```

### ğŸ’¡ é‡é»è§€å¿µ

> **å•é¡Œå®šç¾©æ±ºå®šäº†ä¸€åˆ‡ã€‚** é¸éŒ¯æŒ‡æ¨™ã€æéŒ¯ç›®æ¨™ã€å¿½ç•¥é™åˆ¶æ¢ä»¶ï¼Œ
> å†å¥½çš„æ¨¡å‹ä¹Ÿæ²’ç”¨ã€‚èŠ± 20% çš„æ™‚é–“åœ¨å•é¡Œå®šç¾©ä¸Šï¼Œå¯ä»¥ç¯€çœ
> 80% èµ°å†¤æ‰è·¯çš„æ™‚é–“ã€‚

---

## 17.3 è³‡æ–™è™•ç†ï¼šåƒåœ¾é€²ï¼Œåƒåœ¾å‡º

### è³‡æ–™è™•ç†æµç¨‹åœ–

```
åŸå§‹è³‡æ–™
    â”‚
    â”œâ”€â”€ 1. è³‡æ–™æ¢ç´¢ (EDA)
    â”‚   â”œâ”€â”€ è³‡æ–™å‹æ…‹æª¢æŸ¥
    â”‚   â”œâ”€â”€ ç¼ºå¤±å€¼çµ±è¨ˆ
    â”‚   â”œâ”€â”€ åˆ†å¸ƒåœ– & æè¿°çµ±è¨ˆ
    â”‚   â””â”€â”€ ç›¸é—œæ€§åˆ†æ
    â”‚
    â”œâ”€â”€ 2. è³‡æ–™æ¸…ç†
    â”‚   â”œâ”€â”€ è™•ç†ç¼ºå¤±å€¼
    â”‚   â”œâ”€â”€ è™•ç†ç•°å¸¸å€¼
    â”‚   â”œâ”€â”€ ä¿®æ­£è³‡æ–™å‹æ…‹
    â”‚   â””â”€â”€ è™•ç†é‡è¤‡è³‡æ–™
    â”‚
    â”œâ”€â”€ 3. ç‰¹å¾µå·¥ç¨‹
    â”‚   â”œâ”€â”€ ç·¨ç¢¼é¡åˆ¥è®Šæ•¸
    â”‚   â”œâ”€â”€ ç‰¹å¾µç¸®æ”¾
    â”‚   â”œâ”€â”€ ç‰¹å¾µé¸æ“‡
    â”‚   â””â”€â”€ ç‰¹å¾µå‰µé€ 
    â”‚
    â””â”€â”€ 4. è³‡æ–™åˆ†å‰²
        â”œâ”€â”€ Train / Validation / Test
        â””â”€â”€ æ³¨æ„ï¼šæ™‚é–“åºåˆ—è¦æŒ‰æ™‚é–“åˆ†å‰²ï¼

    âš ï¸  æ‰€æœ‰è½‰æ›éƒ½è¦ fit on train, transform on test
```

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# === EDA æ¨¡æ¿ ===
def quick_eda(df, target_col=None):
    """å¿«é€Ÿè³‡æ–™æ¢ç´¢"""
    print("="*50)
    print(f"è³‡æ–™å½¢ç‹€: {df.shape}")
    print(f"æ¬„ä½æ•¸: {df.shape[1]}")
    print(f"æ¨£æœ¬æ•¸: {df.shape[0]}")
    print("="*50)

    print("\n--- è³‡æ–™å‹æ…‹ ---")
    print(df.dtypes.value_counts())

    print("\n--- ç¼ºå¤±å€¼ ---")
    missing = df.isnull().sum()
    missing_pct = (missing / len(df)) * 100
    missing_df = pd.DataFrame({
        'Count': missing,
        'Percentage': missing_pct
    })
    print(missing_df[missing_df['Count'] > 0].sort_values(
        'Percentage', ascending=False
    ))

    print("\n--- æè¿°çµ±è¨ˆ ---")
    print(df.describe())

    if target_col:
        print(f"\n--- ç›®æ¨™è®Šæ•¸åˆ†å¸ƒ ({target_col}) ---")
        print(df[target_col].value_counts(normalize=True))


# === å»ºç«‹è™•ç† Pipeline ===
def build_preprocessing_pipeline(numeric_features, categorical_features):
    """å»ºç«‹è³‡æ–™å‰è™•ç†ç®¡ç·š"""

    numeric_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])

    categorical_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', LabelEncoder())  # å¯¦éš›ä¸Šç”¨ OneHotEncoder æ›´å¥½
    ])

    # æ³¨æ„ï¼šå¯¦éš›ç”¨ ColumnTransformer çµ„åˆ
    preprocessor = ColumnTransformer([
        ('num', numeric_pipeline, numeric_features),
        ('cat', categorical_pipeline, categorical_features)
    ])

    return preprocessor
```

### âš ï¸ å¸¸è¦‹é™·é˜±

```
é™·é˜± 1ï¼šåœ¨æ•´å€‹è³‡æ–™é›†ä¸Šåš fit_transform
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âŒ scaler.fit_transform(X)  # åŒ…å« test çš„è³‡è¨Š â†’ è³‡æ–™æ´©æ¼ï¼
âœ… scaler.fit(X_train)
   X_train = scaler.transform(X_train)
   X_test = scaler.transform(X_test)

é™·é˜± 2ï¼šæ™‚é–“åºåˆ—ç”¨éš¨æ©Ÿåˆ†å‰²
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âŒ train_test_split(X, y, random_state=42)  # æœªä¾†è³‡æ–™æ··å…¥è¨“ç·´é›†
âœ… æŒ‰æ™‚é–“é †åºåˆ†å‰²ï¼Œç”¨éå»é æ¸¬æœªä¾†

é™·é˜± 3ï¼šEDA åšå¾—ä¸å¤ 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
èŠ±åœ¨ EDA ä¸Šçš„æ¯ä¸€åˆ†é˜ï¼Œéƒ½èƒ½åœ¨å»ºæ¨¡æ™‚çœä¸‹ååˆ†é˜ã€‚
ä¸è¦æ€¥è‘—è·‘æ¨¡å‹ï¼å…ˆç†è§£ä½ çš„è³‡æ–™ã€‚

é™·é˜± 4ï¼šå¿˜è¨˜è™•ç†é¡åˆ¥è®Šæ•¸çš„æ–°é¡åˆ¥
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å¦‚æœ test ä¸­å‡ºç¾äº† train æ²’æœ‰çš„é¡åˆ¥å€¼æ€éº¼è¾¦ï¼Ÿ
éœ€è¦æœ‰ handle_unknown='ignore' çš„ç­–ç•¥ã€‚
```

---

## 17.4 æ¨¡å‹æ¯”è¼ƒï¼šè‡³å°‘ä¸‰ç¨®ï¼Œä½†è¦æœ‰ç†ç”±

### æ¨¡å‹é¸æ“‡ç­–ç•¥

```
å¦‚ä½•é¸æ“‡è¦æ¯”è¼ƒçš„æ¨¡å‹ï¼Ÿ

  è³‡æ–™ç‰¹æ€§                 å»ºè­°æ¨¡å‹çµ„åˆ
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  å°è³‡æ–™é›† (<1K)     â†’    LR, SVM, KNN
  ä¸­è³‡æ–™é›† (1K-100K) â†’    RF, GBM, SVM
  å¤§è³‡æ–™é›† (>100K)   â†’    GBM, LR, Neural Net
  éœ€è¦å¯è§£é‡‹æ€§       â†’    LR, DT, Rule-based
  é«˜ç¶­åº¦è³‡æ–™         â†’    LR+L1, RF, PCA+æ¨¡å‹
  ä¸å¹³è¡¡è³‡æ–™         â†’    RF(balanced), GBM, LR(balanced)

æœ€ä½³å¯¦è¸ï¼šé¸æ“‡ä¸åŒã€Œå®¶æ—ã€çš„æ¨¡å‹
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ç·šæ€§å®¶æ—ï¼šLogistic Regression, SVM (linear) â”‚
  â”‚ æ¨¹å®¶æ—ï¼š  Random Forest, GBM, XGBoost       â”‚
  â”‚ è·é›¢å®¶æ—ï¼šKNN, SVM (RBF)                    â”‚
  â”‚ é›†æˆå®¶æ—ï¼šVoting, Stacking                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import (
    RandomForestClassifier,
    GradientBoostingClassifier
)
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer, f1_score
import time

# === æ¨¡å‹æ¯”è¼ƒæ¡†æ¶ ===
def compare_models(X_train, y_train, scoring='f1'):
    """
    æ¯”è¼ƒå¤šå€‹æ¨¡å‹çš„ cross-validation è¡¨ç¾
    """
    models = {
        'Logistic Regression': LogisticRegression(
            max_iter=1000, random_state=42
        ),
        'Random Forest': RandomForestClassifier(
            n_estimators=100, random_state=42
        ),
        'Gradient Boosting': GradientBoostingClassifier(
            n_estimators=100, random_state=42
        ),
    }

    results = {}

    print(f"{'Model':<25} {'Mean':>8} {'Std':>8} {'Time':>8}")
    print("-" * 55)

    for name, model in models.items():
        start = time.time()

        scores = cross_val_score(
            model, X_train, y_train,
            cv=5, scoring=scoring, n_jobs=-1
        )

        elapsed = time.time() - start

        results[name] = {
            'mean': scores.mean(),
            'std': scores.std(),
            'scores': scores,
            'time': elapsed
        }

        print(f"{name:<25} {scores.mean():>8.4f} {scores.std():>8.4f} {elapsed:>7.1f}s")

    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
    best = max(results, key=lambda x: results[x]['mean'])
    print(f"\næœ€ä½³æ¨¡å‹: {best} (Mean {scoring}: {results[best]['mean']:.4f})")

    return results


# === ä½¿ç”¨ç¯„ä¾‹ ===
# results = compare_models(X_train, y_train, scoring='f1')
```

### â“ æ²’æœ‰ç¬¨å•é¡Œ

**Qï¼šåªæ¯”è¼ƒ 3 å€‹æ¨¡å‹å¤ å—ï¼Ÿ**
> Aï¼š3 å€‹æ˜¯æœ€ä½è¦æ±‚ã€‚é‡é»ä¸æ˜¯æ•¸é‡ï¼Œè€Œæ˜¯ã€Œå¤šæ¨£æ€§ã€ã€‚
> é¸æ“‡ä¸åŒé¡å‹çš„æ¨¡å‹ï¼ˆç·šæ€§ã€æ¨¹ã€è·é›¢ï¼‰ï¼Œé€™æ¨£ä½ æ‰èƒ½äº†è§£
> ä»€éº¼é¡å‹çš„æ–¹æ³•æœ€é©åˆä½ çš„å•é¡Œã€‚

**Qï¼šå¦‚æœå…©å€‹æ¨¡å‹è¡¨ç¾å·®ä¸å¤šæ€éº¼è¾¦ï¼Ÿ**
> Aï¼šé€™æ™‚å€™è€ƒæ…®å…¶ä»–å› ç´ ï¼šå¯è§£é‡‹æ€§ã€è¨“ç·´/æ¨è«–é€Ÿåº¦ã€
> å°æ–°è³‡æ–™çš„ç©©å¥æ€§ã€ç¶­è­·æˆæœ¬ã€‚æ›´ç°¡å–®çš„æ¨¡å‹é€šå¸¸æ›´å¥½ã€‚

**Qï¼šä¸€å®šè¦ç”¨ scikit-learn çš„æ¨¡å‹å—ï¼Ÿ**
> Aï¼šä¸ä¸€å®šã€‚ä½ å¯ä»¥ç”¨ XGBoostã€LightGBM ç­‰ã€‚ä½†ç¢ºä¿
> ä½ ç†è§£æ¯å€‹æ¨¡å‹çš„åŸç†ï¼Œä¸è¦åªæ˜¯ã€Œè©¦è©¦çœ‹ã€ã€‚

---

## 17.5 Cross Validationï¼šå¯é çš„æ¨¡å‹è©•ä¼°

### Cross Validation ç­–ç•¥é¸æ“‡

```
ä½ çš„è³‡æ–™æ˜¯ä»€éº¼é¡å‹ï¼Ÿ

  â”œâ”€â”€ ä¸€èˆ¬è³‡æ–™ï¼ˆi.i.d.ï¼‰
  â”‚   â”œâ”€â”€ è³‡æ–™é‡è¶³å¤  â†’ K-Fold CV (K=5 æˆ– 10)
  â”‚   â”œâ”€â”€ è³‡æ–™é‡å°‘   â†’ Leave-One-Out CV
  â”‚   â””â”€â”€ ä¸å¹³è¡¡     â†’ Stratified K-Fold CV
  â”‚
  â”œâ”€â”€ æ™‚é–“åºåˆ—
  â”‚   â””â”€â”€ TimeSeriesSplitï¼ˆåªç”¨éå»é æ¸¬æœªä¾†ï¼‰
  â”‚
  â””â”€â”€ ç¾¤çµ„è³‡æ–™ï¼ˆåŒä¸€äººå¤šç­†ï¼‰
      â””â”€â”€ GroupKFoldï¼ˆåŒä¸€ç¾¤çµ„ä¸è·¨ foldï¼‰
```

```python
from sklearn.model_selection import (
    cross_validate,
    StratifiedKFold,
    RepeatedStratifiedKFold
)

# === å®Œæ•´çš„ Cross Validation å ±å‘Š ===
def detailed_cv_report(model, X, y, cv=5):
    """
    ç”Ÿæˆè©³ç´°çš„ cross-validation å ±å‘Š
    """
    scoring = {
        'accuracy': 'accuracy',
        'precision': 'precision',
        'recall': 'recall',
        'f1': 'f1',
        'roc_auc': 'roc_auc'
    }

    # ä½¿ç”¨ Stratified K-Fold ç¢ºä¿æ¯å€‹ fold çš„é¡åˆ¥æ¯”ä¾‹ä¸€è‡´
    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)

    results = cross_validate(
        model, X, y,
        cv=skf,
        scoring=scoring,
        return_train_score=True,
        n_jobs=-1
    )

    print("="*60)
    print("Cross-Validation å ±å‘Š")
    print("="*60)

    print(f"\n{'Metric':<15} {'Train Mean':>12} {'Test Mean':>12} {'Test Std':>10} {'Gap':>8}")
    print("-"*60)

    for metric in scoring:
        train_key = f'train_{metric}'
        test_key = f'test_{metric}'

        train_mean = results[train_key].mean()
        test_mean = results[test_key].mean()
        test_std = results[test_key].std()
        gap = train_mean - test_mean

        # æ¨™è¨˜å¯èƒ½çš„å•é¡Œ
        flag = ""
        if gap > 0.1:
            flag = " âš ï¸ éæ“¬åˆ"
        elif test_std > 0.1:
            flag = " âš ï¸ ä¸ç©©å®š"

        print(f"{metric:<15} {train_mean:>12.4f} {test_mean:>12.4f} "
              f"{test_std:>10.4f} {gap:>8.4f}{flag}")

    print(f"\nè¨“ç·´æ™‚é–“: {results['fit_time'].mean():.2f}s (avg)")

    return results

# === ä½¿ç”¨ç¯„ä¾‹ ===
# results = detailed_cv_report(model, X_train, y_train, cv=5)
```

---

## 17.6 Bias-Variance åˆ†æ

### ç”¨å­¸ç¿’æ›²ç·šè¨ºæ–·å•é¡Œ

```
é«˜åå·® (Underfitting)ï¼š            é«˜è®Šç•° (Overfitting)ï¼š

Score                              Score
  ^                                  ^
  |  --------- training             |  --------- training
  |                                  |
  |                                  |
  |  --------- validation           |
  |                                  |  --------- validation
  |                                  |
  +-------------------->            +-------------------->
    Training Set Size                 Training Set Size

å…©æ¢ç·šéƒ½ä½ä¸”æ¥è¿‘                    å…©æ¢ç·šå·®è·å¤§
â†’ æ¨¡å‹å¤ªç°¡å–®                        â†’ æ¨¡å‹å¤ªè¤‡é›œ
â†’ åŠ ç‰¹å¾µã€ç”¨æ›´è¤‡é›œçš„æ¨¡å‹            â†’ åŠ æ­£å‰‡åŒ–ã€æ¸›ç‰¹å¾µã€åŠ è³‡æ–™
```

```python
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
import numpy as np

def plot_learning_curve(estimator, X, y, title="Learning Curve",
                        cv=5, scoring='f1'):
    """
    ç¹ªè£½å­¸ç¿’æ›²ç·šï¼Œè¨ºæ–· bias-variance å•é¡Œ
    """
    train_sizes, train_scores, val_scores = learning_curve(
        estimator, X, y,
        cv=cv,
        scoring=scoring,
        train_sizes=np.linspace(0.1, 1.0, 10),
        n_jobs=-1,
        random_state=42
    )

    train_mean = train_scores.mean(axis=1)
    train_std = train_scores.std(axis=1)
    val_mean = val_scores.mean(axis=1)
    val_std = val_scores.std(axis=1)

    plt.figure(figsize=(10, 6))
    plt.title(title)

    # è¨“ç·´åˆ†æ•¸
    plt.plot(train_sizes, train_mean, 'o-', color='blue',
             label=f'Training {scoring}')
    plt.fill_between(train_sizes,
                     train_mean - train_std,
                     train_mean + train_std,
                     alpha=0.1, color='blue')

    # é©—è­‰åˆ†æ•¸
    plt.plot(train_sizes, val_mean, 'o-', color='red',
             label=f'Validation {scoring}')
    plt.fill_between(train_sizes,
                     val_mean - val_std,
                     val_mean + val_std,
                     alpha=0.1, color='red')

    plt.xlabel('Training Set Size')
    plt.ylabel(scoring)
    plt.legend(loc='best')
    plt.grid(True)

    # è¨ºæ–·
    gap = train_mean[-1] - val_mean[-1]
    print(f"\n=== Bias-Variance è¨ºæ–· ===")
    print(f"æœ€çµ‚ Training {scoring}: {train_mean[-1]:.4f}")
    print(f"æœ€çµ‚ Validation {scoring}: {val_mean[-1]:.4f}")
    print(f"Gap: {gap:.4f}")

    if gap > 0.15:
        print("è¨ºæ–·: é«˜è®Šç•° (Overfitting)")
        print("å»ºè­°: å¢åŠ æ­£å‰‡åŒ–ã€æ¸›å°‘ç‰¹å¾µã€æ”¶é›†æ›´å¤šè³‡æ–™")
    elif val_mean[-1] < 0.6:
        print("è¨ºæ–·: é«˜åå·® (Underfitting)")
        print("å»ºè­°: ä½¿ç”¨æ›´è¤‡é›œçš„æ¨¡å‹ã€å¢åŠ ç‰¹å¾µã€æ¸›å°‘æ­£å‰‡åŒ–")
    else:
        print("è¨ºæ–·: æ¨¡å‹è¡¨ç¾è‰¯å¥½")

    plt.tight_layout()
    plt.show()

    return train_sizes, train_mean, val_mean
```

### ğŸ§  å‹•å‹•è…¦

> ä½ çš„æ¨¡å‹ training accuracy æ˜¯ 99%ï¼Œä½† validation accuracy åªæœ‰ 72%ã€‚
>
> 1. é€™æ˜¯ high bias é‚„æ˜¯ high varianceï¼Ÿ
> 2. ä»¥ä¸‹å“ªäº›ç­–ç•¥å¯èƒ½æœ‰æ•ˆï¼Ÿ
>    a) æ”¶é›†æ›´å¤šè³‡æ–™
>    b) å¢åŠ æ›´å¤šç‰¹å¾µ
>    c) å¢åŠ æ­£å‰‡åŒ–
>    d) ä½¿ç”¨æ›´ç°¡å–®çš„æ¨¡å‹
>    e) ä½¿ç”¨æ›´è¤‡é›œçš„æ¨¡å‹
>    f) æ¸›å°‘ç‰¹å¾µæ•¸é‡

---

## 17.7 è©•ä¼°åˆ†æèˆ‡å•†æ¥­å»ºè­°

### è©•ä¼°å ±å‘Šæ¨¡æ¿

```python
def generate_evaluation_report(model, X_test, y_test, model_name="Model"):
    """
    ç”Ÿæˆå®Œæ•´çš„æ¨¡å‹è©•ä¼°å ±å‘Š
    """
    from sklearn.metrics import (
        classification_report, confusion_matrix,
        roc_auc_score, roc_curve,
        precision_recall_curve, average_precision_score
    )

    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]

    print("="*60)
    print(f"  æ¨¡å‹è©•ä¼°å ±å‘Šï¼š{model_name}")
    print("="*60)

    # 1. åŸºæœ¬æŒ‡æ¨™
    print("\n--- 1. åˆ†é¡å ±å‘Š ---")
    print(classification_report(y_test, y_pred))

    # 2. æ··æ·†çŸ©é™£
    print("--- 2. æ··æ·†çŸ©é™£ ---")
    cm = confusion_matrix(y_test, y_pred)
    print(f"               Predicted")
    print(f"               Neg    Pos")
    print(f"  Actual Neg [{cm[0,0]:>5}  {cm[0,1]:>5}]")
    print(f"  Actual Pos [{cm[1,0]:>5}  {cm[1,1]:>5}]")

    # 3. AUC-ROC
    auc = roc_auc_score(y_test, y_prob)
    print(f"\n--- 3. AUC-ROC: {auc:.4f} ---")

    # 4. å•†æ¥­å½±éŸ¿åˆ†æ
    tn, fp, fn, tp = cm.ravel()
    total = len(y_test)

    print("\n--- 4. å•†æ¥­å½±éŸ¿åˆ†æ ---")
    print(f"  æ­£ç¢ºè™•ç†çš„æ¡ˆä¾‹: {(tp+tn)/total*100:.1f}%")
    print(f"  èª¤å ± (False Positive): {fp} ä»¶ ({fp/total*100:.1f}%)")
    print(f"    â†’ å¯èƒ½çš„æˆæœ¬: ä¸å¿…è¦çš„ä»‹å…¥/èª¿æŸ¥")
    print(f"  æ¼å ± (False Negative): {fn} ä»¶ ({fn/total*100:.1f}%)")
    print(f"    â†’ å¯èƒ½çš„æˆæœ¬: éŒ¯éçœŸæ­£éœ€è¦è™•ç†çš„æ¡ˆä¾‹")

    return {
        'auc': auc,
        'confusion_matrix': cm,
        'y_pred': y_pred,
        'y_prob': y_prob
    }
```

### å•†æ¥­å»ºè­°çš„å¯«æ³•

```
+----------------------------------------------------------+
|  å•†æ¥­å»ºè­°æ’°å¯«æ¡†æ¶                                          |
+----------------------------------------------------------+
|                                                            |
|  1. åŸ·è¡Œæ‘˜è¦ï¼ˆ30 ç§’ç‰ˆï¼‰                                   |
|     "æˆ‘å€‘çš„æ¨¡å‹å¯ä»¥åœ¨ XX å ´æ™¯ä¸‹ï¼Œå°‡ YY æå‡ ZZ%ï¼Œ         |
|      é ä¼°æ¯å¹´å¯ç¯€çœ/å‰µé€  $$$ã€‚"                            |
|                                                            |
|  2. æ¨¡å‹è¡¨ç¾æ‘˜è¦ï¼ˆéæŠ€è¡“èªè¨€ï¼‰                             |
|     "åœ¨ 1000 å€‹æ¸¬è©¦æ¡ˆä¾‹ä¸­ï¼Œæ¨¡å‹ï¼š                          |
|      - æ­£ç¢ºè­˜åˆ¥äº† 85% çš„ç›®æ¨™å®¢æˆ¶                           |
|      - æ¯ 10 å€‹é æ¸¬ä¸­æœ‰ 7 å€‹æ˜¯æ­£ç¢ºçš„                       |
|      - æ¯”ç¾æœ‰æ–¹æ³•æå‡äº† 20%"                               |
|                                                            |
|  3. é¢¨éšªèˆ‡é™åˆ¶ï¼ˆèª å¯¦é¢å°ï¼‰                                 |
|     "æ¨¡å‹åœ¨ä»¥ä¸‹æƒ…æ³å¯èƒ½è¡¨ç¾ä¸ä½³ï¼š                          |
|      - æ–°å®¢æˆ¶ï¼ˆç¼ºå°‘æ­·å²è³‡æ–™ï¼‰                              |
|      - ç‰¹æ®Šä¿ƒéŠ·æœŸé–“ï¼ˆè¡Œç‚ºæ¨¡å¼æ”¹è®Šï¼‰                        |
|      - æŸäº›å®¢ç¾¤ï¼ˆè³‡æ–™ä¸è¶³ï¼‰"                               |
|                                                            |
|  4. éƒ¨ç½²å»ºè­°                                               |
|     "å»ºè­°åˆ†éšæ®µéƒ¨ç½²ï¼š                                      |
|      Phase 1: å°è¦æ¨¡æ¸¬è©¦ (A/B test)                       |
|      Phase 2: æ“´å¤§ç¯„åœï¼Œå»ºç«‹ç›£æ§                           |
|      Phase 3: å…¨é¢éƒ¨ç½²ï¼ŒæŒçºŒå„ªåŒ–"                          |
|                                                            |
|  5. ä¸‹ä¸€æ­¥è¡Œå‹•                                             |
|     å…·é«”çš„ã€å¯åŸ·è¡Œçš„ä¸‹ä¸€æ­¥å»ºè­°                             |
|                                                            |
+----------------------------------------------------------+
```

---

## 17.8 äº¤ä»˜é …ç›®æ¸…å–®

### å¿…è¦äº¤ä»˜é …ç›®

```
ä½ çš„ GitHub Repo çµæ§‹æ‡‰è©²åƒé€™æ¨£ï¼š

my-ml-project/
â”œâ”€â”€ README.md                 â† å°ˆæ¡ˆèªªæ˜ï¼ˆæœ€é‡è¦çš„æª”æ¡ˆï¼ï¼‰
â”œâ”€â”€ requirements.txt          â† å¥—ä»¶ä¾è³´
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  â† åŸå§‹è³‡æ–™ï¼ˆæˆ–è³‡æ–™ä¸‹è¼‰èªªæ˜ï¼‰
â”‚   â””â”€â”€ processed/            â† è™•ç†å¾Œçš„è³‡æ–™
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb          â† è³‡æ–™æ¢ç´¢
â”‚   â”œâ”€â”€ 02_preprocessing.ipynbâ† è³‡æ–™å‰è™•ç†
â”‚   â”œâ”€â”€ 03_modeling.ipynb     â† æ¨¡å‹è¨“ç·´èˆ‡æ¯”è¼ƒ
â”‚   â””â”€â”€ 04_evaluation.ipynb   â† è©•ä¼°èˆ‡åˆ†æ
â”œâ”€â”€ src/                      â† ï¼ˆé€²éšï¼‰å¯é‡ç”¨çš„ç¨‹å¼ç¢¼
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â””â”€â”€ eval_utils.py
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/              â† åœ–è¡¨
â”‚   â””â”€â”€ evaluation_report.md  â† è©•ä¼°å ±å‘Š
â””â”€â”€ presentation/
    â””â”€â”€ slides.pdf            â† ç™¼è¡¨ç°¡å ±
```

### README æ¨¡æ¿

```markdown
# å°ˆæ¡ˆåç¨±

## å•é¡Œæè¿°
ï¼ˆ2-3 å¥è©±èªªæ˜ä½ åœ¨è§£æ±ºä»€éº¼å•é¡Œï¼‰

## è³‡æ–™ä¾†æº
- ä¾†æºï¼š
- æ¨£æœ¬æ•¸ï¼š
- ç‰¹å¾µæ•¸ï¼š
- ç›®æ¨™è®Šæ•¸ï¼š

## æ–¹æ³•
### è³‡æ–™å‰è™•ç†
- ...

### æ¨¡å‹æ¯”è¼ƒ
| æ¨¡å‹ | Accuracy | F1 | AUC-ROC | è¨“ç·´æ™‚é–“ |
|------|----------|-----|---------|---------|
| ...  | ...      | ... | ...     | ...     |

### æœ€ä½³æ¨¡å‹
- é¸æ“‡äº† XXX æ¨¡å‹ï¼Œå› ç‚º...

## çµæœ
ï¼ˆé—œéµç™¼ç¾ï¼Œç”¨éæŠ€è¡“èªè¨€ï¼‰

## æ¨¡å‹é™åˆ¶
ï¼ˆèª å¯¦èªªæ˜æ¨¡å‹çš„é™åˆ¶å’Œé©ç”¨ç¯„åœï¼‰

## å¦‚ä½•å¾©ç¾
```bash
pip install -r requirements.txt
jupyter notebook notebooks/01_EDA.ipynb
```

## æœªä¾†æ”¹é€²æ–¹å‘
-ï¼ˆå¦‚æœæœ‰æ›´å¤šæ™‚é–“/è³‡æ–™ï¼Œä½ æœƒåšä»€éº¼ï¼Ÿï¼‰
```

### å¯¦é©—æµç¨‹åœ–

```
ä½ éœ€è¦æä¾›ä¸€å¼µæ¸…æ¥šçš„å¯¦é©—æµç¨‹åœ–ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  åŸå§‹è³‡æ–™  â”‚â”€â”€â”€â”€â†’â”‚   EDA        â”‚â”€â”€â”€â”€â†’â”‚  è³‡æ–™å‰è™•ç†   â”‚
â”‚  N ç­†      â”‚     â”‚  åˆ†å¸ƒã€ç›¸é—œæ€§ â”‚     â”‚  ç¼ºå¤±å€¼ã€ç¸®æ”¾ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                      â”‚                      â”‚
                      v                      v
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Train Set    â”‚     â”‚  Test Set     â”‚
              â”‚  (80%)        â”‚     â”‚  (20%)        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
          â”‚           â”‚           â”‚          â”‚
          v           v           v          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚ Model A â”‚ â”‚ Model B â”‚ â”‚ Model C â”‚    â”‚
    â”‚ (LR)    â”‚ â”‚ (RF)    â”‚ â”‚ (GBM)   â”‚    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
          â”‚           â”‚           â”‚          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                      â”‚ 5-Fold CV            â”‚
                      v                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
              â”‚  æœ€ä½³æ¨¡å‹é¸æ“‡  â”‚               â”‚
              â”‚  + èª¿åƒ        â”‚               â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                      â”‚                      â”‚
                      v                      v
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      æœ€çµ‚è©•ä¼° (Test Set)       â”‚
              â”‚  Accuracy, F1, AUC-ROC,      â”‚
              â”‚  Confusion Matrix, å­¸ç¿’æ›²ç·š   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             v
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      å•†æ¥­å»ºè­°èˆ‡é™åˆ¶è¨è«–        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 17.9 è©•åˆ†æ¨™æº–

### ğŸ’¡ é‡é»è§€å¿µ

> **æµç¨‹æ­£ç¢ºæ¯” accuracy é«˜æ›´é‡è¦ã€‚**
> ä¸€å€‹ accuracy åªæœ‰ 75% ä½†æµç¨‹å®Œæ•´ã€åˆ†ææ·±å…¥çš„å°ˆæ¡ˆï¼Œ
> é å‹é accuracy 95% ä½†æ²’æœ‰ cross validationã€
> æ²’æœ‰ bias-variance åˆ†æçš„å°ˆæ¡ˆã€‚

### è©•åˆ†è¦æº– (Rubric)

```
+--------------------------------------------------------------+
|  è©•åˆ†é …ç›®                 | é…åˆ† | å„ªç§€ | è‰¯å¥½ | å¾…æ”¹é€²       |
+--------------------------------------------------------------+
|                           |      |      |      |              |
|  1. å•é¡Œå®šç¾©              | 15%  |      |      |              |
|     - æ¸…æ™°åº¦              |  5%  | ç›®æ¨™æ˜ç¢º | ç¨æ¨¡ç³Š | ä¸æ¸…æ¥š  |
|     - æŒ‡æ¨™é¸æ“‡åˆç†æ€§      |  5%  | æœ‰è§£é‡‹ | é¸äº†ä½†æ²’è§£é‡‹ | æ²’é¸|
|     - æ¥­å‹™è„ˆçµ¡            |  5%  | å®Œæ•´ | éƒ¨åˆ† | ç¼ºå°‘        |
|                           |      |      |      |              |
|  2. è³‡æ–™è™•ç†              | 20%  |      |      |              |
|     - EDA å®Œæ•´æ€§          |  8%  | æ·±å…¥ | åŸºæœ¬ | è‰ç‡        |
|     - å‰è™•ç†æ­£ç¢ºæ€§        |  7%  | ç„¡æ´©æ¼ | å°å•é¡Œ | æœ‰æ´©æ¼  |
|     - ç‰¹å¾µå·¥ç¨‹            |  5%  | æœ‰å‰µæ„ | åŸºæœ¬ | æ²’åš      |
|                           |      |      |      |              |
|  3. æ¨¡å‹æ¯”è¼ƒ              | 20%  |      |      |              |
|     - è‡³å°‘ 3 ç¨®æ¨¡å‹       |  5%  | 3+ ç¨® | 2 ç¨® | 1 ç¨®      |
|     - é¸æ“‡æœ‰ç†ç”±          |  5%  | æœ‰è§£é‡‹ | å°‘è§£é‡‹ | æ²’è§£é‡‹  |
|     - Cross Validation    |  5%  | æ­£ç¢ºä½¿ç”¨ | æœ‰ç”¨ä½†æœ‰å•é¡Œ | æ²’ç”¨|
|     - è¶…åƒæ•¸èª¿æ•´          |  5%  | GridSearch | æ‰‹å‹• | é è¨­  |
|                           |      |      |      |              |
|  4. åˆ†ææ·±åº¦              | 20%  |      |      |              |
|     - Bias-Variance åˆ†æ  |  7%  | æœ‰æ›²ç·š+è§£è®€ | æœ‰æ›²ç·š | æ²’åš|
|     - éŒ¯èª¤åˆ†æ            |  7%  | æ·±å…¥ | åŸºæœ¬ | æ²’åš      |
|     - æ¨¡å‹é™åˆ¶è¨è«–        |  6%  | èª å¯¦æ·±å…¥ | æåˆ° | æ²’æ  |
|                           |      |      |      |              |
|  5. å•†æ¥­å»ºè­°              | 10%  |      |      |              |
|     - å¯è¡Œæ€§              |  5%  | å…·é«”å¯åŸ·è¡Œ | å¤ªç± çµ± | æ²’æœ‰|
|     - é¢¨éšªè©•ä¼°            |  5%  | æœ‰è€ƒé‡ | å°‘æ | æ²’æœ‰     |
|                           |      |      |      |              |
|  6. å ±å‘Šèˆ‡ç°¡å ±å“è³ª        | 15%  |      |      |              |
|     - README å®Œæ•´æ€§       |  5%  | å®Œæ•´ | åŸºæœ¬ | ç¼ºå°‘      |
|     - ç¨‹å¼ç¢¼å“è³ª          |  5%  | æ¸…æ¥šè¨»è§£ | å¯è®€ | æ··äº‚  |
|     - ç°¡å ±è¡¨é”            |  5%  | æ¸…æ¥šå°ˆæ¥­ | åŸºæœ¬ | ä¸æ¸…æ¥š|
|                           |      |      |      |              |
+--------------------------------------------------------------+
|  ç¸½åˆ†                     | 100% |                            |
+--------------------------------------------------------------+

åŠ åˆ†é …ç›® (Bonus):
  + ä½¿ç”¨ Pipeline å»ºç«‹å®Œæ•´æµç¨‹
  + åšäº†å…¬å¹³æ€§/å€«ç†åˆ†æï¼ˆç¬¬ 16 ç« ï¼‰
  + éƒ¨ç½²äº† demoï¼ˆStreamlit / Gradioï¼‰
  + åšäº†ç‰¹å¾µé‡è¦æ€§çš„æ·±å…¥åˆ†æ
  + ä½¿ç”¨äº† SHAP æˆ– LIME åšå¯è§£é‡‹æ€§
```

---

## 17.10 å°ˆæ¡ˆæ¨¡æ¿èˆ‡ Checklist

### æœŸæœ«å°ˆæ¡ˆæª¢æŸ¥æ¸…å–®

```
+----------------------------------------------------------+
|  æœŸæœ«å°ˆæ¡ˆå®Œæˆåº¦è‡ªæˆ‘æª¢æŸ¥                                    |
+----------------------------------------------------------+
|                                                            |
|  â–¡ å•é¡Œå®šç¾©                                               |
|    â–¡ å•é¡Œæè¿°æ¸…æ¥š                                         |
|    â–¡ ç›®æ¨™è®Šæ•¸å®šç¾©æ˜ç¢º                                     |
|    â–¡ æˆåŠŸæ¨™æº–å·²è¨­å®š                                       |
|    â–¡ å½±éŸ¿åˆ†æå·²å®Œæˆ                                       |
|                                                            |
|  â–¡ è³‡æ–™è™•ç†                                               |
|    â–¡ EDA å ±å‘Šå®Œæˆ                                         |
|    â–¡ ç¼ºå¤±å€¼å·²è™•ç†                                         |
|    â–¡ è³‡æ–™åˆ†å‰²æ­£ç¢ºï¼ˆç„¡è³‡æ–™æ´©æ¼ï¼‰                           |
|    â–¡ å‰è™•ç† Pipeline å»ºç«‹                                 |
|                                                            |
|  â–¡ æ¨¡å‹æ¯”è¼ƒ                                               |
|    â–¡ è‡³å°‘ 3 ç¨®ä¸åŒé¡å‹çš„æ¨¡å‹                              |
|    â–¡ æ¯å€‹æ¨¡å‹æœ‰ 5-Fold CV çµæœ                            |
|    â–¡ æ¨¡å‹é¸æ“‡æœ‰æ˜ç¢ºç†ç”±                                   |
|    â–¡ è¶…åƒæ•¸èª¿æ•´å·²å®Œæˆ                                     |
|                                                            |
|  â–¡ åˆ†æ                                                   |
|    â–¡ å­¸ç¿’æ›²ç·šå·²ç¹ªè£½                                       |
|    â–¡ Bias-Variance è¨ºæ–·å·²å®Œæˆ                             |
|    â–¡ æ··æ·†çŸ©é™£å·²åˆ†æ                                       |
|    â–¡ éŒ¯èª¤åˆ†æå·²å®Œæˆ                                       |
|    â–¡ ç‰¹å¾µé‡è¦æ€§å·²åˆ†æ                                     |
|                                                            |
|  â–¡ å ±å‘Š                                                   |
|    â–¡ æ¨¡å‹é™åˆ¶å·²è¨è«–                                       |
|    â–¡ å•†æ¥­å»ºè­°å·²æ’°å¯«                                       |
|    â–¡ è©•ä¼°å ±å‘Šå®Œæ•´                                         |
|                                                            |
|  â–¡ äº¤ä»˜ç‰©                                                 |
|    â–¡ GitHub Repo æ•´ç†ä¹¾æ·¨                                 |
|    â–¡ README å®Œæ•´                                          |
|    â–¡ requirements.txt æ­£ç¢º                                |
|    â–¡ ç¨‹å¼ç¢¼æœ‰è¨»è§£                                         |
|    â–¡ ç°¡å ± slides æº–å‚™å¥½                                   |
|                                                            |
+----------------------------------------------------------+
```

---

## 17.11 å®Œæ•´ç¯„ä¾‹å°ˆæ¡ˆæ¼”ç·´ï¼šå®¢æˆ¶æµå¤±é æ¸¬

### æ­¥é©Ÿä¸€ï¼šå•é¡Œå®šç¾©

```
æ¥­å‹™èƒŒæ™¯ï¼šæŸé›»ä¿¡å…¬å¸æ¯æœˆæµå¤±ç´„ 5% çš„å®¢æˆ¶ï¼Œ
          æ¯æµå¤±ä¸€å€‹å®¢æˆ¶çš„æˆæœ¬ç´„ç‚º $500ã€‚

ç›®æ¨™ï¼šå»ºç«‹ä¸€å€‹é æ¸¬æ¨¡å‹ï¼Œè­˜åˆ¥å³å°‡æµå¤±çš„å®¢æˆ¶ï¼Œ
      è®“å®¢æœåœ˜éšŠæå‰ä»‹å…¥æŒ½ç•™ã€‚

æˆåŠŸæ¨™æº–ï¼š
  - Recall â‰¥ 0.80ï¼ˆä¸èƒ½éŒ¯éå¤ªå¤šå³å°‡æµå¤±çš„å®¢æˆ¶ï¼‰
  - Precision â‰¥ 0.50ï¼ˆä¸è¦æµªè²»å¤ªå¤šè¡ŒéŠ·è³‡æºåœ¨ä¸æœƒæµå¤±çš„å®¢æˆ¶ä¸Šï¼‰

å½±éŸ¿åˆ†æï¼š
  - False Negativeï¼ˆæ¼å ±ï¼‰ï¼šéŒ¯éå³å°‡æµå¤±çš„å®¢æˆ¶ â†’ æå¤± $500/äºº
  - False Positiveï¼ˆèª¤å ±ï¼‰ï¼šå°ä¸æœƒæµå¤±çš„å®¢æˆ¶åšæŒ½ç•™ â†’ èŠ±è²» $50/äºº
  - FN çš„ä»£åƒ¹æ˜¯ FP çš„ 10 å€ â†’ Recall æ¯” Precision é‡è¦
```

### æ­¥é©ŸäºŒï¼šè³‡æ–™è™•ç†ï¼ˆç¨‹å¼ç¢¼æ‘˜è¦ï¼‰

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

# è¼‰å…¥è³‡æ–™ï¼ˆä»¥ Telco Customer Churn ç‚ºä¾‹ï¼‰
# df = pd.read_csv('data/raw/telco_churn.csv')

# EDA æ‘˜è¦
# quick_eda(df, target_col='Churn')

# è³‡æ–™å‰è™•ç†
numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
categorical_features = ['Contract', 'PaymentMethod', 'InternetService']

preprocessor = ColumnTransformer([
    ('num', Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ]), numeric_features),
    ('cat', Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ]), categorical_features)
])

# åˆ†å‰²è³‡æ–™
# X_train, X_test, y_train, y_test = train_test_split(
#     X, y, test_size=0.2, stratify=y, random_state=42
# )
```

### æ­¥é©Ÿä¸‰ï¼šæ¨¡å‹æ¯”è¼ƒ

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import cross_val_score, GridSearchCV

# ä¸‰å€‹æ¨¡å‹ + Pipeline
models = {
    'Logistic Regression': Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', LogisticRegression(
            class_weight='balanced', max_iter=1000, random_state=42
        ))
    ]),
    'Random Forest': Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(
            class_weight='balanced', n_estimators=100, random_state=42
        ))
    ]),
    'Gradient Boosting': Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', GradientBoostingClassifier(
            n_estimators=100, random_state=42
        ))
    ]),
}

# Cross Validation æ¯”è¼ƒ
# ä½¿ç”¨ recall ä½œç‚ºä¸»è¦æŒ‡æ¨™ï¼ˆå› ç‚º FN ä»£åƒ¹é«˜ï¼‰
for name, model in models.items():
    scores = cross_val_score(
        model, X_train, y_train,
        cv=5, scoring='recall', n_jobs=-1
    )
    print(f"{name}: Recall = {scores.mean():.4f} (+/- {scores.std():.4f})")
```

### æ­¥é©Ÿå››ï¼šè¶…åƒæ•¸èª¿æ•´

```python
# å‡è¨­ GBM è¡¨ç¾æœ€å¥½ï¼Œé€²è¡Œèª¿åƒ
param_grid = {
    'classifier__n_estimators': [100, 200, 300],
    'classifier__max_depth': [3, 5, 7],
    'classifier__learning_rate': [0.01, 0.05, 0.1],
    'classifier__min_samples_leaf': [5, 10, 20]
}

grid_search = GridSearchCV(
    models['Gradient Boosting'],
    param_grid,
    cv=5,
    scoring='recall',
    n_jobs=-1,
    verbose=1
)

# grid_search.fit(X_train, y_train)
# print(f"Best params: {grid_search.best_params_}")
# print(f"Best recall: {grid_search.best_score_:.4f}")
```

### æ­¥é©Ÿäº”ï¼šæœ€çµ‚è©•ä¼°

```python
# ç”¨æœ€ä½³æ¨¡å‹åœ¨ Test Set ä¸Šåšæœ€çµ‚è©•ä¼°
# best_model = grid_search.best_estimator_
# report = generate_evaluation_report(best_model, X_test, y_test, "GBM (Tuned)")

# å­¸ç¿’æ›²ç·š
# plot_learning_curve(best_model, X_train, y_train, scoring='recall')
```

### æ­¥é©Ÿå…­ï¼šå•†æ¥­å»ºè­°

```
+----------------------------------------------------------+
|  å•†æ¥­å»ºè­°ï¼šå®¢æˆ¶æµå¤±é æ¸¬æ¨¡å‹                               |
+----------------------------------------------------------+
|                                                            |
|  åŸ·è¡Œæ‘˜è¦ï¼š                                               |
|  æˆ‘å€‘çš„æ¨¡å‹å¯ä»¥è­˜åˆ¥å‡º 82% å³å°‡æµå¤±çš„å®¢æˆ¶ï¼Œ               |
|  å¦‚æœå°é€™äº›å®¢æˆ¶é€²è¡ŒæŒ½ç•™ï¼Œé ä¼°æ¯æœˆå¯æ¸›å°‘                   |
|  150 ä½å®¢æˆ¶æµå¤±ï¼Œç¯€çœç´„ $75,000/æœˆã€‚                     |
|                                                            |
|  éƒ¨ç½²å»ºè­°ï¼š                                               |
|  Phase 1 (ç¬¬ 1 æœˆ)ï¼š                                      |
|    - åœ¨ 10% çš„å®¢ç¾¤ä¸Šé€²è¡Œ A/B æ¸¬è©¦                        |
|    - å»ºç«‹è‡ªå‹•åŒ–çš„æŒ½ç•™è§¸ç™¼æµç¨‹                             |
|                                                            |
|  Phase 2 (ç¬¬ 2-3 æœˆ)ï¼š                                    |
|    - æ“´å¤§åˆ° 50%ï¼Œæ ¹æ“šæ¸¬è©¦çµæœèª¿æ•´                        |
|    - å»ºç«‹æ¨¡å‹è¡¨ç¾ç›£æ§ dashboard                           |
|                                                            |
|  Phase 3 (ç¬¬ 4 æœˆèµ·)ï¼š                                    |
|    - å…¨é¢éƒ¨ç½²                                             |
|    - æ¯æœˆé‡æ–°è©•ä¼°æ¨¡å‹è¡¨ç¾                                 |
|    - æ¯å­£é‡æ–°è¨“ç·´æ¨¡å‹                                     |
|                                                            |
|  é¢¨éšªèˆ‡é™åˆ¶ï¼š                                              |
|  - æ¨¡å‹åŸºæ–¼æ­·å²è³‡æ–™ï¼Œå¸‚å ´ç’°å¢ƒè®ŠåŒ–å¯èƒ½å½±éŸ¿æº–ç¢ºæ€§           |
|  - æ–°å®¢æˆ¶ï¼ˆ< 3 å€‹æœˆï¼‰çš„é æ¸¬å¯é æ€§è¼ƒä½                    |
|  - å»ºè­°æ­é…äººå·¥åˆ¤æ–·ï¼Œä¸è¦å®Œå…¨è‡ªå‹•åŒ–                       |
|                                                            |
+----------------------------------------------------------+
```

---

## 17.12 æœŸæœ«ç™¼è¡¨æŠ€å·§

### ç°¡å ±çµæ§‹å»ºè­°ï¼ˆ10 åˆ†é˜ç™¼è¡¨ï¼‰

```
æ™‚é–“åˆ†é…ï¼š
+----------------------------------------------------------+
|  1. å•é¡Œèˆ‡å‹•æ©Ÿ (2 min)                                    |
|     - ç‚ºä»€éº¼é€™å€‹å•é¡Œé‡è¦ï¼Ÿ                                |
|     - ä½ ç”¨ä»€éº¼è³‡æ–™ï¼Ÿ                                      |
|                                                            |
|  2. æ–¹æ³• (3 min)                                          |
|     - è³‡æ–™è™•ç†é‡é»                                        |
|     - æ¨¡å‹é¸æ“‡èˆ‡æ¯”è¼ƒçµæœ                                  |
|     - ä¸è¦å¿µç¨‹å¼ç¢¼ï¼ç”¨åœ–è¡¨å’Œçµæœ                          |
|                                                            |
|  3. çµæœèˆ‡åˆ†æ (3 min)                                    |
|     - æœ€ä½³æ¨¡å‹çš„è¡¨ç¾                                      |
|     - é—œéµç™¼ç¾ï¼ˆç‰¹å¾µé‡è¦æ€§ã€éŒ¯èª¤åˆ†æï¼‰                    |
|     - å­¸åˆ°äº†ä»€éº¼ï¼Ÿ                                        |
|                                                            |
|  4. çµè«–èˆ‡å»ºè­° (2 min)                                    |
|     - å•†æ¥­åƒ¹å€¼                                            |
|     - æ¨¡å‹é™åˆ¶                                            |
|     - æœªä¾†æ”¹é€²æ–¹å‘                                        |
+----------------------------------------------------------+
```

### âš ï¸ å¸¸è¦‹é™·é˜±

```
é™·é˜± 1ï¼šç°¡å ±ä¸Šæ”¾å¤ªå¤šç¨‹å¼ç¢¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
è½çœ¾çœ‹ä¸æ‡‚å¯†å¯†éº»éº»çš„ç¨‹å¼ç¢¼ã€‚
ç”¨åœ–è¡¨ã€è¡¨æ ¼ã€é‡é»çµæœå–ä»£ã€‚

é™·é˜± 2ï¼šåªè¬›æŠ€è¡“ï¼Œä¸è¬›æ•…äº‹
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æœ€å¥½çš„ ML ç°¡å ±æ˜¯åœ¨è¬›ä¸€å€‹æ•…äº‹ï¼š
"æœ‰ä¸€å€‹å•é¡Œ â†’ æˆ‘å€‘å¦‚ä½•è§£æ±º â†’ çµæœå¦‚ä½• â†’ æ¥ä¸‹ä¾†æ€éº¼è¾¦"

é™·é˜± 3ï¼šå¿½ç•¥æ¨¡å‹çš„é™åˆ¶
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ‰¿èªé™åˆ¶ä¸æ˜¯å¼±é»ï¼Œæ˜¯å°ˆæ¥­çš„è¡¨ç¾ã€‚
æ¯å€‹æ¨¡å‹éƒ½æœ‰é™åˆ¶ï¼Œèƒ½èªªå‡ºä¾†ä»£è¡¨ä½ çœŸçš„ç†è§£ã€‚

é™·é˜± 4ï¼šæ²’æœ‰æº–å‚™ demo
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å¦‚æœå¯ä»¥çš„è©±ï¼Œæº–å‚™ä¸€å€‹ç°¡å–®çš„ demoã€‚
çœ‹åˆ°æ¨¡å‹ã€Œæ´»è‘—ã€é‹ä½œï¼Œæ¯”çœ‹ slides æœ‰èªªæœåŠ› 100 å€ã€‚

é™·é˜± 5ï¼šè¶…æ™‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç·´ç¿’ï¼Œç·´ç¿’ï¼Œå†ç·´ç¿’ã€‚
10 åˆ†é˜çš„ç°¡å ±è‡³å°‘ç·´ 3 éã€‚
```

### â“ æ²’æœ‰ç¬¨å•é¡Œ

**Qï¼šæˆ‘çš„æ¨¡å‹è¡¨ç¾ä¸å¥½æ€éº¼è¾¦ï¼Ÿ**
> Aï¼šè¡¨ç¾ä¸å¥½ä¸ä»£è¡¨å°ˆæ¡ˆå¤±æ•—ï¼é‡è¦çš„æ˜¯ä½ çš„åˆ†æï¼š
> ç‚ºä»€éº¼è¡¨ç¾ä¸å¥½ï¼Ÿè³‡æ–™ä¸è¶³ï¼Ÿç‰¹å¾µä¸å¤ ï¼Ÿå•é¡Œæœ¬èº«å¾ˆé›£ï¼Ÿ
> å¥½çš„åˆ†ææ¯”å¥½çš„ accuracy æ›´æœ‰åƒ¹å€¼ã€‚

**Qï¼šå¯ä»¥ç”¨ ChatGPT / Copilot å¹«å¿™å¯«ç¨‹å¼å—ï¼Ÿ**
> Aï¼šå¯ä»¥ä½œç‚ºå·¥å…·ä½¿ç”¨ï¼Œä½†ä½ å¿…é ˆç†è§£æ¯ä¸€è¡Œç¨‹å¼ç¢¼çš„å«ç¾©ã€‚
> å¦‚æœè¢«å•åˆ°ã€Œé€™è¡Œåœ¨åšä»€éº¼ï¼Ÿã€ä½ ç­”ä¸å‡ºä¾†ï¼Œé‚£å°±æ˜¯å•é¡Œã€‚
> AI æ˜¯åŠ©æ‰‹ï¼Œä¸æ˜¯ä»£ç­†ã€‚

**Qï¼šè³‡æ–™é›†è¦è‡ªå·±æ‰¾å—ï¼Ÿ**
> Aï¼šå»ºè­°ä½¿ç”¨å…¬é–‹è³‡æ–™é›†ï¼ˆKaggle, UCI ML Repository,
> Google Dataset Searchï¼‰ã€‚é¸æ“‡ä½ æ„Ÿèˆˆè¶£çš„é ˜åŸŸï¼Œ
> é€™æ¨£åšå°ˆæ¡ˆæœƒæ›´æœ‰å‹•åŠ›ã€‚

**Qï¼šå¯ä»¥åšå›æ­¸å•é¡Œå—ï¼Ÿé‚„æ˜¯ä¸€å®šè¦åˆ†é¡ï¼Ÿ**
> Aï¼šéƒ½å¯ä»¥ï¼é¸æ“‡é©åˆä½ è³‡æ–™å’Œå•é¡Œçš„é¡å‹ã€‚
> å›æ­¸å’Œåˆ†é¡çš„å°ˆæ¡ˆæµç¨‹å…¶å¯¦å¾ˆé¡ä¼¼ï¼Œ
> å·®åˆ¥ä¸»è¦åœ¨è©•ä¼°æŒ‡æ¨™çš„é¸æ“‡ã€‚

---

## ğŸ“ èª²å¾Œç·´ç¿’

### ç·´ç¿’ 1ï¼šå°ˆæ¡ˆææ¡ˆæ›¸
```
å¯«ä¸€ä»½ 1 é çš„å°ˆæ¡ˆææ¡ˆæ›¸ï¼ŒåŒ…å«ï¼š
1. å•é¡Œæè¿°ï¼ˆ2-3 å¥ï¼‰
2. è³‡æ–™ä¾†æºï¼ˆå¾å“ªè£¡å–å¾—ã€å¤§å°ï¼‰
3. é è¨ˆä½¿ç”¨çš„æ–¹æ³•
4. æˆåŠŸæ¨™æº–
5. æ™‚é–“è¦åŠƒï¼ˆ2 é€±ï¼‰
```

### ç·´ç¿’ 2ï¼šMini å°ˆæ¡ˆ
```
é¸æ“‡ sklearn çš„å…§å»ºè³‡æ–™é›†ï¼Œå®Œæˆä»¥ä¸‹æµç¨‹ï¼š
1. EDAï¼ˆè‡³å°‘ 5 å¼µåœ–ï¼‰
2. å‰è™•ç†ï¼ˆä½¿ç”¨ Pipelineï¼‰
3. æ¯”è¼ƒ 3 å€‹æ¨¡å‹ï¼ˆä½¿ç”¨ cross_val_scoreï¼‰
4. å­¸ç¿’æ›²ç·šåˆ†æ
5. æœ€çµ‚è©•ä¼°å ±å‘Š
6. é™åˆ¶è¨è«–ï¼ˆè‡³å°‘ 3 é»ï¼‰

é™æ™‚ï¼š4 å°æ™‚
```

### ç·´ç¿’ 3ï¼šäº’è©•
```
å’ŒåŒå­¸äº¤æ›å°ˆæ¡ˆï¼Œä¾ç…§è©•åˆ†è¦æº– (Rubric) äº’è©•ã€‚
ç‰¹åˆ¥æ³¨æ„ï¼š
1. æœ‰æ²’æœ‰è³‡æ–™æ´©æ¼ï¼Ÿ
2. Cross validation ç”¨æ³•æ­£ç¢ºå—ï¼Ÿ
3. æ¨¡å‹é¸æ“‡æœ‰é“ç†å—ï¼Ÿ
4. é™åˆ¶è¨è«–æ˜¯å¦èª å¯¦ï¼Ÿ
```

---

> **æ­å–œä½ ï¼** å®Œæˆäº†æ•´é–€ scikit-learn èª²ç¨‹ã€‚
> è¨˜ä½ï¼šML ä¸æ˜¯çµ‚é»ï¼Œè€Œæ˜¯èµ·é»ã€‚
> ä¿æŒå¥½å¥‡å¿ƒï¼ŒæŒçºŒå­¸ç¿’ï¼Œæœ€é‡è¦çš„æ˜¯ â€” å‹•æ‰‹åšå°ˆæ¡ˆï¼
>
> ã€Œç´™ä¸Šå¾—ä¾†çµ‚è¦ºæ·ºï¼Œçµ•çŸ¥æ­¤äº‹è¦èº¬è¡Œã€‚ã€â€” é™¸æ¸¸
