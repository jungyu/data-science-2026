# Chapter 5：可治理 RAG 設計

> **本章定位**：記憶系統設計。讓你的 AI 有可靠的「記憶」，而且每一段記憶都可以追溯。
>
> 「RAG 不是讓 AI 更聰明，是讓 AI 更誠實。」

---

## RAG 到底在解決什麼問題？

### AI 的原罪：幻覺（Hallucination）

```
你問：「公司的退貨政策是什麼？」

沒有 RAG 的 AI：
  「根據一般做法，退貨政策通常是 30 天內可退。」
  → 它在猜！你公司的政策可能是 14 天，也可能是 60 天。

有 RAG 的 AI：
  「根據《客戶服務手冊 v3.2》(p.12)，退貨政策為：
   購買後 14 個營業日內，商品保持原包裝可退貨。」
  → 它在查！答案來自你的文件，可以驗證。
```

### RAG 的本質

```
RAG = Retrieval Augmented Generation
      ─────────  ─────────  ──────────
      檢索        增強       生成

用白話說：
  1. 先去找相關資料（Retrieval）
  2. 把找到的資料餵給 AI（Augmented）
  3. AI 基於這些資料生成回答（Generation）

關鍵差異：
  沒 RAG → AI 用自己的「記憶」（訓練資料）回答 → 可能過時或錯誤
  有 RAG → AI 用你的「文件」回答 → 即時且可驗證
```

---

## RAG 完整流程

```
┌─────────────────────────────────────────────────────┐
│                  RAG Pipeline                        │
│                                                       │
│  ┌─────────────────────────────────────────────┐    │
│  │ Phase 1: Ingestion（匯入）                    │    │
│  │                                               │    │
│  │  文件 → 解析 → 切割 → 向量化 → 儲存索引      │    │
│  │  PDF     提取    Chunk   Embedding  Vector DB │    │
│  └─────────────────────────────────────────────┘    │
│                                                       │
│  ┌─────────────────────────────────────────────┐    │
│  │ Phase 2: Retrieval（檢索）                    │    │
│  │                                               │    │
│  │  問題 → 向量化 → 相似度搜尋 → 取回 Top-K     │    │
│  │  Query   Embedding  Cosine     Chunks        │    │
│  └─────────────────────────────────────────────┘    │
│                                                       │
│  ┌─────────────────────────────────────────────┐    │
│  │ Phase 3: Generation（生成）                   │    │
│  │                                               │    │
│  │  Chunks + 問題 → AI 生成 → 附加 Citation     │    │
│  │  Context   Query   Answer    Source ref      │    │
│  └─────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────┘
```

---

## Phase 1：Ingestion（匯入）

### Step 1：文件解析

```
支援格式與解析策略：

PDF
  → 提取文字 + 保留頁碼
  → 表格要特殊處理（轉成結構化資料）
  → 圖片中的文字用 OCR

Markdown
  → 保留標題層級作為 metadata
  → 程式碼區塊要特殊標記

TXT / CSV
  → 純文字直接處理
  → CSV 保留欄位名稱作為 context

注意事項：
  ✓ 保留所有 metadata（檔名、頁碼、章節標題）
  ✗ 不要丟掉格式資訊（它有語意價值）
```

### Step 2：Chunk 策略（文件切割）

這是 RAG 品質的**關鍵決定**。

```
類比：你在讀一本書，要做筆記卡片。
  - 一張卡片太大（一整章）→ 找的時候太慢
  - 一張卡片太小（一句話）→ 缺乏上下文
  - 剛剛好（一個段落）→ 容易找、有上下文
```

#### 策略一：固定大小切割

```
設定：每 500 tokens 切一塊，重疊 50 tokens

原文：
  [段落 A - 200 tokens][段落 B - 400 tokens][段落 C - 300 tokens]

切割結果：
  Chunk 1: [段落 A 全部 + 段落 B 前 300 tokens]  = 500 tokens
  Chunk 2: [段落 B 後 50 tokens(重疊) + 段落 B 剩餘 + 段落 C 前 150]  = 500 tokens
  Chunk 3: [段落 C 後 50 tokens(重疊) + 段落 C 剩餘 + ...]  = ...

優點：簡單、可預測
缺點：可能把一個概念切成兩半
```

#### 策略二：語意切割

```
按照文件結構切割（標題、段落、章節）

原文（Markdown）：
  ## 退貨政策
  購買後 14 天內可退貨...
  特殊商品不適用...

  ## 換貨政策
  同款商品可直接換貨...

切割結果：
  Chunk 1: { title: "退貨政策", content: "購買後 14 天內可退貨..." }
  Chunk 2: { title: "換貨政策", content: "同款商品可直接換貨..." }

優點：保持語意完整性
缺點：chunk 大小不均
```

#### 策略三：混合策略（推薦）

```
1. 先按語意結構切割（章節、段落）
2. 如果某個 chunk 太大（> 800 tokens）→ 再用固定大小切
3. 如果某個 chunk 太小（< 100 tokens）→ 跟相鄰的合併
4. 所有 chunk 加 50 tokens overlap

結果：
  - 語意完整
  - 大小可控
  - 邊界有重疊（不遺漏）
```

### Chunk Metadata 規格

每個 chunk 必須攜帶以下 metadata：

```json
{
  "chunk_id": "doc_001_chunk_005",
  "document_id": "doc_001",
  "document_name": "customer-service-manual-v3.2.pdf",
  "document_version": "3.2",
  "chunk_index": 5,
  "total_chunks": 42,
  "page_number": 12,
  "section_title": "退貨政策",
  "content": "購買後 14 個營業日內，商品保持原包裝可退貨...",
  "token_count": 456,
  "created_at": "2025-12-01T10:00:00Z",
  "embedding_model": "text-embedding-3-small"
}
```

### Step 3：向量化（Embedding）

```
Chunk 的文字內容 → Embedding 模型 → 向量（一串數字）

例如：
  "購買後 14 天內可退貨" → [0.023, -0.156, 0.891, ..., 0.045]
                                    （1536 維向量）

這個向量代表了這段文字的「語意」。
語意相近的文字，向量也會相近。
```

### Step 4：儲存索引

```
向量 + Metadata → Vector Database

常見的 Vector DB：
  - Supabase pgvector（推薦：跟現有 DB 整合）
  - ChromaDB（適合本地開發）
  - Pinecone（雲端服務）
  - Qdrant（開源、高效能）
```

---

## Phase 2：Retrieval（檢索）

### 搜尋流程

```
使用者問題：「退貨要在幾天內？」

Step 1：向量化問題
  "退貨要在幾天內？" → [0.031, -0.142, 0.876, ..., 0.052]

Step 2：相似度搜尋
  在向量庫中找出最相似的 Top-K chunks
  （用 Cosine Similarity 計算）

Step 3：相關性過濾
  Score > 0.7 → 納入 context
  Score < 0.7 → 丟棄（不夠相關）

Step 4：回傳結果
  [
    { chunk: "購買後 14 天內可退貨...", score: 0.92, source: "p.12" },
    { chunk: "退貨運費由買方負擔...", score: 0.85, source: "p.13" },
    { chunk: "換貨不適用退貨政策...", score: 0.71, source: "p.14" }
  ]
```

### 檢索品質的兩大指標

```
Precision（精確率）：
  找回來的結果中，有多少是真正相關的？
  → 精確率低 = 找了一堆不相關的
  → 解法：提高相關性閾值

Recall（召回率）：
  所有相關的結果中，有多少被找回來了？
  → 召回率低 = 漏掉了重要資料
  → 解法：增加 Top-K 數量、降低閾值

兩者要平衡：
  閾值太高 → 精確但可能漏掉
  閾值太低 → 全面但可能有雜訊
  推薦：先以 Recall 為主，再用 Reranker 提升 Precision
```

---

## Phase 3：Generation（生成）

### Citation 格式標準

```
三種引用格式：

1. 行內引用（Inline Citation）
   「退貨期限為 14 天 [kb://manual.pdf, p.12]」
   → 適合簡短回答

2. 段落引用（Block Citation）
   > 根據《客服手冊 v3.2》第 12 頁：
   > 「購買後 14 個營業日內，商品保持原包裝可退貨。」
   → 適合需要精確引述的場合

3. 來源附錄（Source Appendix）
   [回答內容]

   來源：
   1. kb://customer-service-manual-v3.2.pdf, p.12
   2. kb://return-policy-update-2025.md, §3
   → 適合較長的綜合性回答
```

### 「找不到答案」的正確處理

```
❌ 錯誤：AI 自己編一個答案
   「退貨政策是 30 天。」（知識庫裡根本沒有這個資訊）

❌ 也錯誤：直接說不知道
   「抱歉，我不知道。」（沒有提供任何幫助）

✅ 正確：誠實告知 + 提供替代方案
   「在目前的知識庫中，我沒有找到關於 [具體主題] 的資訊。
    建議您：
    1. 聯繫客服部門確認最新政策
    2. 查看公司內部文件系統的 '政策' 分類
    最接近的相關資訊是：[列出部分相關的結果]」
```

---

## 防止 Hallucination 的結構設計

### 五道防線

```
防線 1：Retrieval Gate（檢索閘門）
  → 如果最高相關性分數 < 0.5，直接告知找不到
  → 不讓 AI「硬回答」

防線 2：Source Grounding（來源紮根）
  → 回答中的每個事實都必須對應到一個 chunk
  → 無法對應的事實不能出現

防線 3：Confidence Scoring（信心評分）
  → 基於多少個 chunk 支持這個回答
  → 只有 1 個 chunk → medium confidence
  → 3+ 個 chunk 互相佐證 → high confidence

防線 4：Contradiction Detection（矛盾偵測）
  → 如果不同 chunk 說的不一樣
  → 明確告知使用者存在矛盾
  → 「文件 A (v2.0) 說 14 天，文件 B (v1.5) 說 30 天，
     建議以較新版本為準。」

防線 5：Human Review Trigger（人工審核觸發）
  → 信心度 < medium 時標記需要人工確認
  → 涉及法律/醫療/財務時一律觸發
```

---

## 知識庫版本控制

### 為什麼需要版本控制？

```
場景：公司在 2025 年 6 月更新了退貨政策。

沒有版本控制：
  知識庫同時存在新舊政策
  AI 可能引用舊政策回答
  使用者收到過期資訊

有版本控制：
  v3.1（舊）：30 天退貨
  v3.2（新）：14 天退貨
  AI 自動引用最新版本
  舊版本標記為 "archived"
```

### 版本控制策略

```yaml
versioning:
  scheme: semantic  # major.minor（重大變更.小幅更新）

  lifecycle:
    draft: "草稿，不進入 RAG 索引"
    active: "正式版，進入 RAG 索引"
    archived: "已歸檔，不再被檢索"
    deprecated: "即將下架，檢索時附加警告"

  rules:
    - 新版本上傳後，舊版本自動轉為 archived
    - archived 文件不被檢索，但保留備查
    - 如果使用者明確要求歷史版本，可以特別查詢
    - 版本變更記錄在日誌中
```

### KB 更新流程

```
新文件上傳
  │
  ├── ① 格式驗證（是否支援的格式？）
  │     └── 不支援 → 回報錯誤
  │
  ├── ② 重複檢測（是否已有同名文件？）
  │     └── 已存在 → 版本升級流程
  │
  ├── ③ 切割 + 向量化
  │     └── 產生 chunks + embeddings
  │
  ├── ④ 索引更新
  │     └── 新 chunks 加入向量庫
  │     └── 舊版本 chunks 標記 archived
  │
  ├── ⑤ 版本標記
  │     └── 記錄版本號、時間、操作者
  │
  └── ⑥ 驗證
        └── 用測試問題確認新文件可被正確檢索
```

---

## 動手做：設計你的 RAG 系統

### 練習 5-1：Chunk 策略設計

拿一份你熟悉的文件（例如學校的選課手冊或公司的員工手冊），設計 chunk 策略：

| 決策項目 | 你的選擇 | 為什麼 |
|----------|----------|--------|
| 切割策略 | 固定/語意/混合 | |
| Chunk 大小 | ___ tokens | |
| Overlap | ___ tokens | |
| 相關性閾值 | ___ | |
| Top-K | ___ | |

### 練習 5-2：Citation 格式設計

為以下三種場景設計 citation 格式：

1. 使用者問一個簡單的事實性問題
2. 使用者問一個需要綜合多個來源的分析問題
3. 知識庫裡找不到答案的情況

### 練習 5-3：Hallucination 防護測試

設計五個可能讓 RAG 產生幻覺的「陷阱問題」：

```markdown
| # | 陷阱問題 | 預期的幻覺 | 你的防護機制 |
|---|----------|-----------|-------------|
| 1 | [問知識庫沒有的資訊] | | |
| 2 | [問過期的資訊] | | |
| 3 | [問矛盾的資訊] | | |
| 4 | [問需要推理的問題] | | |
| 5 | [問跨領域的問題] | | |
```

---

## 本章重點回顧

```
┌─────────────────────────────────────────────┐
│          可治理 RAG 七大記憶點                 │
│                                               │
│  1. RAG = 檢索 + 增強 + 生成                 │
│  2. Chunk 策略決定 RAG 品質                   │
│  3. 每個回答都要有 Citation                   │
│  4. 找不到就誠實說，不要編                     │
│  5. 五道防線對抗 Hallucination                │
│  6. 知識庫要有版本控制                         │
│  7. 更新流程要自動化 + 可驗證                  │
└─────────────────────────────────────────────┘
```

---

## 下一章預告

RAG 設計好了，接下來要設計「規則」。

在 [Chapter 6：Agent 治理模型](06-mcp-governance.md) 中，你會學到：
- 為什麼 AI Agent 需要「法律」
- Read-only policy 的實作
- Human-in-the-loop 的設計模式
- 審計紀錄的標準

讓你的 AI 在「法治」下運作。
