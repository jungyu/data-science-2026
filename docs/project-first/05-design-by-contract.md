# ç¬¬äº”ç« ï¼šå¥‘ç´„å…ˆè¡Œ â€” çŸ¥è­˜ API çš„åˆç´„æ²»ç†

## å­¸ç¿’ç›®æ¨™

è®€å®Œæœ¬ç« ï¼Œä½ å°‡èƒ½å¤ ï¼š
- å°‡ Design by Contract çš„ä¸‰è¦ç´ æ‡‰ç”¨åˆ° RAG çš„çŸ¥è­˜ API è¨­è¨ˆ
- ç†è§£ Retrieval Gate å¦‚ä½•é˜²æ­¢ä½å“è³ªçŸ¥è­˜é€²å…¥æŸ¥è©¢ç®¡ç·š
- åˆ—èˆ‰ RAG çŸ¥è­˜ç³»çµ±çš„å…­å¤§æ²»ç†é–˜é–€åŠå…¶è§¸ç™¼æ¢ä»¶
- èªªæ˜ Knowledge Drift Detection å¦‚ä½•é˜²æ­¢çŸ¥è­˜åº«å“è³ªä¸‹æ»‘

---

## 5.1 Design by Contract in RAG

### çŸ¥è­˜ API çš„åˆç´„ä¸‰è¦ç´ 

**Design by Contract**ï¼ˆDbCï¼‰æœ€åˆç”± Bertrand Meyer åœ¨ 1986 å¹´æå‡ºï¼Œ  
å®šç¾©å‡½å¼çš„ã€Œå‰ç½®æ¢ä»¶ã€å¾Œç½®æ¢ä»¶ã€ä¸è®Šé‡ã€ã€‚  
åœ¨ RAG ç³»çµ±ä¸­ï¼Œé€™å€‹æ¦‚å¿µæ‡‰ç”¨åˆ°æ¯å€‹çŸ¥è­˜æ“ä½œï¼š

```python
# æª”æ¡ˆï¼šsrc/ingestion/ingestor.py

from dataclasses import dataclass
from typing import Literal

@dataclass
class IngestResult:
    doc_id: str
    chunk_count: int
    namespace: str

class KnowledgeIngestor:

    def ingest(
        self,
        file_path: str,
        namespace: str,
        metadata: dict,
    ) -> IngestResult:
        """
        å°‡ä¸€ä»½æ–‡ä»¶åµŒå…¥ä¸¦å­˜å…¥å‘é‡è³‡æ–™åº«ã€‚

        Preconditionsï¼ˆå‰ç½®æ¢ä»¶ï¼‰ï¼š
          - metadata["status"] == "approved"
          - metadata["last_updated"] è·ä»Šä¸è¶…é 180 å¤©
          - namespace å¿…é ˆæ˜¯å·²æˆæ¬Šçš„ namespaceï¼ˆåœ¨ allowed_namespaces æ¸…å–®ä¸­ï¼‰
          - file_path æŒ‡å‘çš„æª”æ¡ˆå¿…é ˆå­˜åœ¨ä¸”å¯è®€å–

        Postconditionsï¼ˆå¾Œç½®æ¢ä»¶ï¼‰ï¼š
          - å›å‚³çš„ IngestResult.chunk_count >= 1ï¼ˆè‡³å°‘ä¸€å€‹ chunkï¼‰
          - å‘é‡ DB ä¸­ç¢ºå¯¦å­˜åœ¨ chunk_count å€‹å±¬æ–¼æ­¤ doc_id çš„å‘é‡
          - æ¯å€‹ chunk çš„ metadata åŒ…å« sourceã€doc_idã€chunk_index

        Invariantsï¼ˆä¸è®Šé‡ï¼‰ï¼š
          - INV-1: ä»»ä½• chunk çš„ text é•·åº¦ä¸å¾—ç‚º 0
          - INV-2: å¤±æ•—æ™‚å‘é‡ DB ä¸­ä¸å¾—æœ‰æ­¤æ‰¹æ¬¡çš„æ®˜é¤˜ chunkï¼ˆåŸå­æ€§ï¼‰
          - INV-3: namespace å¿…é ˆç¬¦åˆ constitutional å®šç¾©çš„å‘½åè¦ç¯„
        """

        # å‰ç½®æ¢ä»¶é©—è­‰
        self._assert_preconditions(file_path, namespace, metadata)

        # åŸ·è¡Œæ”å–ï¼ˆå¸¶æœ‰ rollback ä¿è­·ï¼‰
        result = self._execute_with_rollback(file_path, namespace, metadata)

        # å¾Œç½®æ¢ä»¶é©—è­‰
        self._assert_postconditions(result)

        return result

    def _assert_preconditions(self, file_path, namespace, metadata):
        """å‰ç½®æ¢ä»¶ï¼šå¤±æ•—æ™‚æ‹‹å‡º PreconditionErrorï¼Œä¸åŸ·è¡Œä»»ä½•å¯«å…¥"""
        from datetime import datetime, timedelta

        if metadata.get("status") != "approved":
            raise PreconditionError(
                f"æ–‡ä»¶å¿…é ˆç‚º approved ç‹€æ…‹ï¼Œç•¶å‰ç‹€æ…‹ï¼š{metadata.get('status')}"
            )

        last_updated = datetime.fromisoformat(metadata["last_updated"])
        if datetime.now() - last_updated > timedelta(days=180):
            raise PreconditionError(
                f"æ–‡ä»¶è¶…é 180 å¤©æœªæ›´æ–°ï¼ˆlast_updated: {metadata['last_updated']}ï¼‰ï¼Œ"
                "è«‹è¯ç¹«æ–‡ä»¶è² è²¬äººå¯©æ ¸å¾Œå†æ”å–"
            )

        if namespace not in self.allowed_namespaces:
            raise PreconditionError(f"æœªæˆæ¬Šçš„ namespace: {namespace}")

    def _assert_postconditions(self, result: IngestResult):
        """å¾Œç½®æ¢ä»¶ï¼šé©—è­‰è³‡æ–™åº«ç‹€æ…‹æ˜¯å¦ç¬¦åˆé æœŸ"""
        actual_count = self.vector_db.count(doc_id=result.doc_id)
        if actual_count != result.chunk_count:
            raise PostconditionError(
                f"å‘é‡ DB ä¸­çš„ chunk æ•¸é‡ï¼ˆ{actual_count}ï¼‰"
                f"èˆ‡å›å‚³å€¼ï¼ˆ{result.chunk_count}ï¼‰ä¸ç¬¦"
            )
```

> ğŸ”‘ **æ²»ç†é‡é»**ï¼šå‰ç½®æ¢ä»¶å’Œå¾Œç½®æ¢ä»¶çš„é©—è­‰ä¸æ˜¯é¸é …ï¼Œæ˜¯**å¼·åˆ¶åŸ·è¡Œçš„åˆç´„**ã€‚  
> ä»»ä½•ç¹éé€™äº›é©—è­‰çš„ç¨‹å¼ç¢¼éƒ½é•åäº† Constitution Principle Iã€‚

---

## 5.2 Retrieval Gateï¼šæª¢ç´¢å“è³ªçš„æ²»ç†é–˜é–€

### ä»€éº¼æ˜¯ Retrieval Gate

**Retrieval Gate** æ˜¯ RAG ç‰ˆçš„ Contract-First Gateï¼š

> åœ¨ç”Ÿæˆç­”æ¡ˆä¹‹å‰ï¼Œå…ˆé©—è­‰ã€Œæª¢ç´¢çµæœçš„å“è³ªæ˜¯å¦ç¬¦åˆæ¨™æº–ã€ã€‚  
> å“è³ªä¸é”æ¨™ â†’ ä¸ç”Ÿæˆç­”æ¡ˆï¼Œæ”¹ç‚ºå›æ‡‰ã€ŒçŸ¥è­˜ä¸è¶³ã€ã€‚

```python
# æª”æ¡ˆï¼šsrc/retrieval/retrieval_gate.py

from dataclasses import dataclass
from typing import Literal

@dataclass
class RetrievalGateResult:
    status: Literal["pass", "block"]
    reason: str | None
    chunks: list[dict]

class RetrievalGate:
    """
    åœ¨ LLM ç”Ÿæˆç­”æ¡ˆå‰ï¼Œé©—è­‰æª¢ç´¢çµæœçš„å“è³ªã€‚
    é€™æ˜¯ RAG çš„ Contract-First Gateã€‚
    """

    MIN_CHUNKS = 1           # è‡³å°‘è¦æœ‰ 1 å€‹ chunk
    MIN_SCORE = 0.72         # å‘é‡ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆä½æ–¼æ­¤å€¼è¦–ç‚ºä¸ç›¸é—œï¼‰
    MAX_AGE_DAYS = 180       # chunk ä¾†æºæ–‡ä»¶çš„æœ€å¤§å¹´é½¡

    def validate(self, query: str, chunks: list[dict]) -> RetrievalGateResult:
        """
        é©—è­‰æª¢ç´¢çµæœæ˜¯å¦å¯ä»¥äº¤çµ¦ LLM ç”Ÿæˆç­”æ¡ˆã€‚

        Args:
            query: ä½¿ç”¨è€…çš„å•é¡Œ
            chunks: å‘é‡ DB è¿”å›çš„ chunksï¼ˆå«ç›¸ä¼¼åº¦åˆ†æ•¸å’Œ metadataï¼‰

        Returns:
            RetrievalGateResultï¼ˆpass/block + åŸå› ï¼‰
        """

        # è¦å‰‡ 1ï¼šå¿…é ˆè‡³å°‘æœ‰ 1 å€‹ chunk
        if len(chunks) < self.MIN_CHUNKS:
            return RetrievalGateResult(
                status="block",
                reason="knowledge_insufficient",
                chunks=[]
            )

        # è¦å‰‡ 2ï¼šæœ€é«˜åˆ†çš„ chunk ç›¸ä¼¼åº¦å¿…é ˆé”åˆ°é–¾å€¼
        top_score = max(c["score"] for c in chunks)
        if top_score < self.MIN_SCORE:
            return RetrievalGateResult(
                status="block",
                reason=f"low_relevance (top score: {top_score:.2f} < {self.MIN_SCORE})",
                chunks=[]
            )

        # è¦å‰‡ 3ï¼šéæ¿¾æ‰éæ™‚çš„ chunksï¼ˆConstitution Principle Iï¼‰
        fresh_chunks = [
            c for c in chunks
            if self._is_fresh(c["metadata"].get("last_updated"))
        ]
        if not fresh_chunks:
            return RetrievalGateResult(
                status="block",
                reason="all_chunks_expired",
                chunks=[]
            )

        # è¦å‰‡ 4ï¼šéæ¿¾æ‰ deprecated æ–‡ä»¶çš„ chunks
        valid_chunks = [
            c for c in fresh_chunks
            if c["metadata"].get("status") != "deprecated"
        ]
        if not valid_chunks:
            return RetrievalGateResult(
                status="block",
                reason="all_chunks_deprecated",
                chunks=[]
            )

        return RetrievalGateResult(status="pass", reason=None, chunks=valid_chunks)

    def _is_fresh(self, last_updated: str | None) -> bool:
        from datetime import datetime, timedelta
        if not last_updated:
            return False
        age = datetime.now() - datetime.fromisoformat(last_updated)
        return age.days <= self.MAX_AGE_DAYS
```

### å®Œæ•´çš„æŸ¥è©¢æµæ°´ç·šï¼ˆå« Gateï¼‰

```python
# æª”æ¡ˆï¼šsrc/query/query_pipeline.py

class RAGQueryPipeline:

    def answer(self, question: str, user_namespace: str) -> dict:
        """
        å®Œæ•´çš„ RAG æŸ¥è©¢æµæ°´ç·šï¼š
        1. åµŒå…¥å•é¡Œ
        2. å‘é‡æœå°‹ï¼ˆé™å®š namespaceï¼‰
        3. Retrieval Gate é©—è­‰
        4. LLM ç”Ÿæˆï¼ˆGate é€šéå¾Œæ‰åŸ·è¡Œï¼‰
        5. è¨˜éŒ„æ—¥èªŒï¼ˆConstitution Principle IVï¼‰
        """

        # Step 1: åµŒå…¥å•é¡Œ
        query_vector = self.embedder.embed(question)

        # Step 2: å‘é‡æœå°‹ï¼ˆå— namespace é™åˆ¶ â€” Principle IIIï¼‰
        raw_chunks = self.vector_db.search(
            vector=query_vector,
            namespace=user_namespace,
            top_k=10,
        )

        # Step 3: Retrieval Gate
        gate_result = self.retrieval_gate.validate(question, raw_chunks)

        if gate_result.status == "block":
            # Gate é˜»æ“‹ â†’ ä¸èª¿ç”¨ LLMï¼Œç›´æ¥å›æ‡‰çŸ¥è­˜ä¸è¶³
            answer = self._knowledge_insufficient_response(gate_result.reason)
            sources = []
        else:
            # Gate é€šé â†’ èª¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆ
            answer, sources = self._generate_answer(
                question, gate_result.chunks
            )

        # Step 4: è¨˜éŒ„æ—¥èªŒï¼ˆä¸è«–æˆåŠŸå¤±æ•—éƒ½è¦è¨˜éŒ„ï¼‰
        self.audit_logger.log({
            "question": question,
            "gate_status": gate_result.status,
            "chunks_used": [c["doc_id"] for c in gate_result.chunks],
            "answer_preview": answer[:100],
        })

        return {
            "answer": answer,
            "sources": sources,
            "gate_status": gate_result.status,
        }
```

---

## 5.3 å…­å¤§æ²»ç†é–˜é–€

| é–˜é–€ | è§¸ç™¼æ¢ä»¶ | ä½œç”¨ |
|------|---------|------|
| **Retrieval Gate** | æ¯æ¬¡æŸ¥è©¢ | é©—è­‰æª¢ç´¢å“è³ªï¼Œé˜²æ­¢ä½å“è³ªçŸ¥è­˜é€²å…¥ LLM |
| **Ingest Gate** | æ¯æ¬¡æ–‡ä»¶æ”å– | é©—è­‰ metadataã€æ–‡ä»¶å¹´é½¡ã€ç‹€æ…‹ |
| **Namespace Gate** | æ–°å¢ namespace | è¦æ±‚ ADR + å­˜å–æ§åˆ¶è¨­è¨ˆ |
| **Model Change Gate** | æ›´æ›åµŒå…¥/ç”Ÿæˆæ¨¡å‹ | è¦æ±‚ A/B è©•ä¼° + åˆ†éšæ®µæ¨å‡º |
| **Knowledge Drift Gate** | å®šæœŸæƒæï¼ˆæ¯é€±ï¼‰ | åµæ¸¬çŸ¥è­˜åº«å“è³ªä¸‹æ»‘ï¼ˆé™³èˆŠæ–‡ä»¶æ¯”ä¾‹ï¼‰ |
| **Audit Gate** | æ¯æœˆ | ç¨½æ ¸ RAG ç­”æ¡ˆå“è³ªå’Œä½¿ç”¨è€…æ»¿æ„åº¦ |

---

## 5.4 Knowledge Drift Detection

### ä»€éº¼æ˜¯çŸ¥è­˜æ¼‚ç§»

RAG ç³»çµ±æœ€å¸¸è¦‹çš„é•·æœŸå•é¡Œä¸æ˜¯æŸå€‹ bugï¼Œè€Œæ˜¯ã€ŒçŸ¥è­˜æ…¢æ…¢è®ŠèˆŠäº†ã€ï¼š

```
ç¬¬ 1 å€‹æœˆï¼š80% çš„æ–‡ä»¶åœ¨æœ‰æ•ˆæœŸå…§ â†’ ç³»çµ±è¡¨ç¾å„ªç§€
ç¬¬ 3 å€‹æœˆï¼š65% çš„æ–‡ä»¶åœ¨æœ‰æ•ˆæœŸå…§ â†’ ç³»çµ±é–‹å§‹å‡ºç¾éæ™‚ç­”æ¡ˆ
ç¬¬ 6 å€‹æœˆï¼š40% çš„æ–‡ä»¶åœ¨æœ‰æ•ˆæœŸå…§ â†’ ç”¨æˆ¶é–‹å§‹æŠ•è¨´ AI èªªçš„å’Œç¾å¯¦ä¸ç¬¦
ç¬¬ 9 å€‹æœˆï¼š20% çš„æ–‡ä»¶åœ¨æœ‰æ•ˆæœŸå…§ â†’ ç³»çµ±åŸºæœ¬ä¸å¯ä¿¡
```

é€™å€‹å•é¡Œå¾ˆéš±è”½ï¼Œå› ç‚ºç³»çµ±ä¸¦æ²’æœ‰ã€Œå‡ºéŒ¯ã€ï¼Œåªæ˜¯å®‰éœåœ°è®Šå·®äº†ã€‚

### Knowledge Drift Detector

```python
# æª”æ¡ˆï¼šsrc/governance/drift_detector.py
# å»ºè­°æ¯é€±ç”± cron job æˆ– GitHub Actions è‡ªå‹•åŸ·è¡Œ

from datetime import datetime, timedelta

class KnowledgeDriftDetector:
    """
    å®šæœŸæƒæçŸ¥è­˜åº«ï¼Œåµæ¸¬å“è³ªä¸‹æ»‘çš„æ—©æœŸè¨Šè™Ÿã€‚
    å°æ‡‰ï¼šConstitution Principle Iï¼ˆçŸ¥è­˜å“è³ªå„ªå…ˆï¼‰
    """

    THRESHOLDS = {
        "fresh_ratio_warning": 0.75,   # æ–°é®®æ–‡ä»¶æ¯”ä¾‹ < 75% ç™¼å‡ºè­¦å‘Š
        "fresh_ratio_critical": 0.60,  # æ–°é®®æ–‡ä»¶æ¯”ä¾‹ < 60% è§¸ç™¼ç·Šæ€¥è™•ç†
        "deprecated_ratio_max": 0.10,  # å»¢æ£„æ–‡ä»¶æ¯”ä¾‹ > 10% éœ€è¦æ¸…ç†
    }

    def run_weekly_scan(self) -> dict:
        """åŸ·è¡Œæ¯é€±çŸ¥è­˜å“è³ªæƒæ"""

        # å¾å‘é‡ DB å–å¾—æ‰€æœ‰æ–‡ä»¶çš„ metadata æ‘˜è¦
        all_docs = self.vector_db.list_documents_metadata()

        report = {}
        for namespace in self.get_all_namespaces():
            ns_docs = [d for d in all_docs if d["namespace"] == namespace]
            report[namespace] = self._analyze_namespace(ns_docs)

        # è§¸ç™¼å‘Šè­¦
        self._trigger_alerts(report)
        return report

    def _analyze_namespace(self, docs: list[dict]) -> dict:
        now = datetime.now()
        total = len(docs)
        if total == 0:
            return {"status": "empty", "total": 0}

        fresh = sum(
            1 for d in docs
            if (now - datetime.fromisoformat(d["last_updated"])).days <= 180
        )
        deprecated = sum(1 for d in docs if d.get("status") == "deprecated")

        fresh_ratio = fresh / total
        deprecated_ratio = deprecated / total

        # åˆ¤å®šç‹€æ…‹
        if fresh_ratio < self.THRESHOLDS["fresh_ratio_critical"]:
            status = "critical"
        elif fresh_ratio < self.THRESHOLDS["fresh_ratio_warning"]:
            status = "warning"
        elif deprecated_ratio > self.THRESHOLDS["deprecated_ratio_max"]:
            status = "needs_cleanup"
        else:
            status = "healthy"

        return {
            "status": status,
            "total_docs": total,
            "fresh_docs": fresh,
            "fresh_ratio": round(fresh_ratio, 3),
            "deprecated_docs": deprecated,
            "oldest_doc": min(d["last_updated"] for d in docs),
        }

    def _trigger_alerts(self, report: dict):
        for namespace, stats in report.items():
            if stats["status"] == "critical":
                self.alert_manager.send_urgent(
                    f"ğŸš¨ [{namespace}] çŸ¥è­˜åº«åš´é‡è€åŒ–ï¼"
                    f"æ–°é®®æ–‡ä»¶æ¯”ä¾‹ï¼š{stats['fresh_ratio']:.0%}ï¼Œ"
                    f"ç«‹å³é€šçŸ¥å„æ–‡ä»¶ owner å¯©æ ¸æ›´æ–°ã€‚"
                )
            elif stats["status"] == "warning":
                self.alert_manager.send_warning(
                    f"âš ï¸ [{namespace}] çŸ¥è­˜åº«é–‹å§‹è€åŒ–ï¼Œ"
                    f"æ–°é®®æ–‡ä»¶æ¯”ä¾‹ï¼š{stats['fresh_ratio']:.0%}"
                )
```

---

## 5.5 ä¸è®Šé‡ï¼ˆInvariantï¼‰çš„ RAG åƒ¹å€¼

æœ¬å°ˆæ¡ˆå®šç¾©çš„ RAG ä¸è®Šé‡ï¼ˆä»¥ INV- ç·¨è™Ÿï¼‰ï¼š

```
INV-1: ä»»ä½• chunk çš„ text é•·åº¦ä¸å¾—ç‚º 0ï¼ˆç©ºç™½ chunk ä¸å¾—å­˜å…¥å‘é‡ DBï¼‰
INV-2: æ”å–å¤±æ•—æ™‚å‘é‡ DB ä¸å¾—æœ‰æ®˜é¤˜ chunkï¼ˆåŸå­æ€§ï¼‰
INV-3: namespace å‘½åå¿…é ˆç¬¦åˆ {department}-{category} æ ¼å¼
INV-4: æ¯å€‹ chunk å¿…é ˆåŒ…å« sourceã€doc_idã€chunk_indexã€last_updated
INV-5: ç¦æ­¢è·¨ namespace çš„å‘é‡æœå°‹ï¼ˆé™¤éç¶“é Namespace Gate å¯©æ ¸ï¼‰
INV-6: ç­”æ¡ˆç”Ÿæˆçš„ temperature ä¸å¾—è¶…é 0.3
```

é€™äº›ä¸è®Šé‡çš„åƒ¹å€¼ï¼š
- **æ˜ç¢º**ï¼šä¸éœ€è¦çŒœæ¸¬ã€Œé€™æ¨£åšå¯ä»¥å—ï¼Ÿã€
- **å¯é©—è­‰**ï¼šå¯ä»¥åœ¨å–®å…ƒæ¸¬è©¦å’Œ CI/CD ä¸­è‡ªå‹•æª¢æŸ¥
- **å¯å…±äº«**ï¼šMCP Serverã€Skillsã€AI Agent éƒ½èƒ½éµå®ˆ

---

## ç·´ç¿’

1. **DbC ç·´ç¿’**ï¼šç‚º `KnowledgeRetriever.search()` å‡½å¼è¨­è¨ˆ preconditionã€postcondition å’Œ invariantï¼š
   - è¼¸å…¥ï¼šqueryï¼ˆå­—ä¸²ï¼‰ã€namespaceï¼ˆå­—ä¸²ï¼‰ã€top_kï¼ˆæ•´æ•¸ï¼‰
   - è¼¸å‡ºï¼šchunks åˆ—è¡¨ï¼ˆå«åˆ†æ•¸å’Œ metadataï¼‰

2. **Gate è¨­è¨ˆç·´ç¿’**ï¼šå‡è¨­ä½ è¦æ–°å¢ä¸€å€‹ã€Œè®“å¤–éƒ¨ä¾›æ‡‰å•†æŸ¥è©¢ç”¢å“ FAQã€çš„åŠŸèƒ½ï¼Œè¨­è¨ˆä¸€å€‹ Vendor Access Gateï¼Œå®šç¾©è§¸ç™¼æ¢ä»¶å’Œæª¢æŸ¥é …ç›®ã€‚

3. **Drift Detection ç·´ç¿’**ï¼šç‚ºä¸€å€‹ã€Œæ¯æœˆå¯©è¨ˆã€çš„ç¨½æ ¸é€±æœŸè¨­è¨ˆå‘Šè­¦è¦å‰‡ï¼Œæ¯”æ¯é€±çš„ drift detector æ›´åš´æ ¼ï¼šéœ€è¦è¿½è¹¤å“ªäº›é¡å¤–çš„æŒ‡æ¨™ï¼ˆä¾‹å¦‚ç­”æ¡ˆè¢«ç”¨æˆ¶æ¨™è¨˜ç‚ºã€Œä¸æ­£ç¢ºã€çš„æ¯”ç‡ï¼‰ï¼Ÿ

4. **æ€è€ƒé¡Œ**ï¼šRetrieval Gate çš„ `MIN_SCORE = 0.72` æ˜¯æ€éº¼æ±ºå®šçš„ï¼Ÿå¦‚æœè¨­å¤ªé«˜ï¼ˆ0.9ï¼‰ï¼Œæœƒæœ‰ä»€éº¼å•é¡Œï¼Ÿè¨­å¤ªä½ï¼ˆ0.5ï¼‰ï¼Œåˆæœ‰ä»€éº¼é¢¨éšªï¼Ÿä½ æœƒå¦‚ä½•ç”¨å¯¦é©—æ•¸æ“šä¾†æ ¡æº–é€™å€‹å€¼ï¼Ÿ

---

> **ä¸‹ä¸€ç« **ï¼š[ç¬¬å…­ç« ï¼šåµŒå…¥å‘é‡èˆ‡åˆ†å¡ŠåŸç†](06-embedding-and-chunking.md)  
> æˆ‘å€‘å°‡æ·±å…¥ç†è§£ Embedding å’Œ Chunking çš„æŠ€è¡“åŸç†ï¼Œé€™æ˜¯ RAG ç³»çµ±çš„ã€Œç·¨è­¯å™¨æ ¸å¿ƒã€ã€‚
